{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Pack Ultra‑Cohérente — Rask × LLM (v5)\n",
    "\n",
    "Objectif: produire des **segments cohérents** en **une seule requête** LLM avec:\n",
    "\n",
    "- Respect **durée → nombre de mots** via `WPM` (cible par segment)\n",
    "- **Fins propres**, **débuts nets**, **pas de phrase coupée**\n",
    "- **Zéro pad foireux** du type `Cet.` ou `Cela.`\n",
    "- **Régénération ciblée** + **normalisation EXACTE** si nécessaire\n",
    "- **Audit vitesse** (WPM réel vs cible) et **audit frontières**\n",
    "\n",
    "Le notebook inclut aussi un correcteur pour **sanitiser un payload JSON existant**, afin de réparer les phrases inachevées et enlever les pads inutiles."
   ],
   "id": "3e8556c5b2b82ca2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) Dépendances\n",
    "\n",
    "Si nécessaire, installez:\n",
    "\n",
    "```bash\n",
    "%pip install --quiet requests python-dotenv pandas tqdm openai\n",
    "```\n",
    "\n",
    "Le notebook n'utilise **pas** d'`ipywidgets` et reste compatible noyaux simples."
   ],
   "id": "91a2932393a65be3"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T19:47:31.044660Z",
     "start_time": "2025-09-28T19:47:31.024256Z"
    }
   },
   "source": [
    "# (1) Configuration & variables d'environnement\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Rask\n",
    "RASK_TOKEN = os.getenv(\"RASK_TOKEN\", \"\")\n",
    "RASK_CLIENT_ID = os.getenv(\"RASK_CLIENT_ID\", \"\")\n",
    "RASK_CLIENT_SECRET = os.getenv(\"RASK_CLIENT_SECRET\", \"\")\n",
    "\n",
    "# OpenAI\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "OPENAI_TEMPERATURE = float(os.getenv(\"OPENAI_TEMPERATURE\", \"0.2\"))\n",
    "OPENAI_MAX_RETRIES = int(os.getenv(\"OPENAI_MAX_RETRIES\", \"2\"))\n",
    "\n",
    "# Paramètres projet\n",
    "LANG_DEST = os.getenv(\"LANG_DEST\", \"fr-fr\")\n",
    "WPM = float(os.getenv(\"WPM\", \"147.0\"))                   # mots/minute cible\n",
    "LENGTH_TOLERANCE = int(os.getenv(\"LENGTH_TOLERANCE\", \"2\"))# ± mots pour première passe\n",
    "MIN_SENT_WORDS = int(os.getenv(\"MIN_SENT_WORDS\", \"7\"))    # bornes indicatives par phrase\n",
    "MAX_SENT_WORDS = int(os.getenv(\"MAX_SENT_WORDS\", \"22\"))\n",
    "RATE_TOL_PCT = float(os.getenv(\"RATE_TOL_PCT\", \"2.0\"))    # tolérance vitesse ±% autour du WPM\n",
    "STRICT_MAX_RETRIES = int(os.getenv(\"STRICT_MAX_RETRIES\", \"7\"))\n",
    "\n",
    "# Sélection du projet (nom ou URL app.rask.ai)\n",
    "PROJECT_SELECTOR = \"4_-_Presentation_des_meches_KtwWjO\"\n",
    "\n",
    "# Scope à traiter (None = tous)\n",
    "SEGMENTS_RANGE = None\n",
    "\n",
    "# Patch\n",
    "DRY_RUN = False         # True: prévisualiser; False: envoyer\n",
    "INCLUDE_TIMING = False # True pour pousser start/end\n",
    "\n",
    "print(\"Config OK —\", {\n",
    "    \"LANG_DEST\": LANG_DEST, \"WPM\": WPM, \"TOL_WORDS\": LENGTH_TOLERANCE,\n",
    "    \"SENT_RANGE\": f\"{MIN_SENT_WORDS}-{MAX_SENT_WORDS}\",\n",
    "    \"RATE_TOL_PCT\": RATE_TOL_PCT,\n",
    "    \"STRICT_MAX_RETRIES\": STRICT_MAX_RETRIES,\n",
    "    \"PROJECT_SELECTOR\": PROJECT_SELECTOR,\n",
    "    \"DRY_RUN\": DRY_RUN, \"INCLUDE_TIMING\": INCLUDE_TIMING\n",
    "})"
   ],
   "id": "42bab772983fec07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config OK — {'LANG_DEST': 'fr-fr', 'WPM': 147.0, 'TOL_WORDS': 2, 'SENT_RANGE': '7-22', 'RATE_TOL_PCT': 2.0, 'STRICT_MAX_RETRIES': 7, 'PROJECT_SELECTOR': '4_-_Presentation_des_meches_KtwWjO', 'DRY_RUN': False, 'INCLUDE_TIMING': False}\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T19:47:31.697003Z",
     "start_time": "2025-09-28T19:47:31.055191Z"
    }
   },
   "source": [
    "# (2) Auth & helpers Rask\n",
    "import re, json, time, math\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import display\n",
    "\n",
    "TOKEN_URL = \"https://rask-prod.auth.us-east-2.amazoncognito.com/oauth2/token\"\n",
    "SCOPES = \"api/source api/input api/output api/limit\"\n",
    "\n",
    "PROJECTS_URL = \"https://api.rask.ai/v2/projects\"\n",
    "GET_PROJECT_URL = \"https://api.rask.ai/v2/projects/{project_id}\"\n",
    "TRANSCRIPTION_URL = \"https://api.rask.ai/v2/projects/{project_id}/transcription\"\n",
    "PATCH_SEGMENTS_URL = \"https://api.rask.ai/v2/projects/{project_id}/transcription/segments\"\n",
    "GENERATE_URL = \"https://api.rask.ai/v2/projects/{project_id}/generate\"\n",
    "\n",
    "def get_token(client_id: str, client_secret: str) -> str:\n",
    "    if not client_id or not client_secret:\n",
    "        raise RuntimeError(\"RASK_CLIENT_ID / RASK_CLIENT_SECRET manquants (ou fournir RASK_TOKEN).\")\n",
    "    r = requests.post(TOKEN_URL, data={\"grant_type\":\"client_credentials\",\"scope\":SCOPES},\n",
    "                      auth=(client_id, client_secret), timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"access_token\"]\n",
    "\n",
    "def build_headers() -> dict:\n",
    "    token = RASK_TOKEN or get_token(RASK_CLIENT_ID, RASK_CLIENT_SECRET)\n",
    "    return {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "HEADERS = build_headers()\n",
    "print(\"Auth Rask OK.\")\n",
    "\n",
    "def _normalize_name(s: str) -> str:\n",
    "    return re.sub(r\"[-\\s_]+\", \"\", (s or \"\").strip().lower())\n",
    "\n",
    "def project_id_from_app_url(url: str) -> str | None:\n",
    "    m = re.search(r\"/project/([0-9a-fA-F-]{36})\", str(url))\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def find_project_id_by_name(headers: dict, name: str, limit: int = 100) -> str | None:\n",
    "    target = _normalize_name(name); offset = 0\n",
    "    while True:\n",
    "        r = requests.get(PROJECTS_URL, headers=headers, params={\"offset\": offset, \"limit\": limit}, timeout=30)\n",
    "        r.raise_for_status(); payload = r.json()\n",
    "        for p in payload.get(\"projects\", []):\n",
    "            if _normalize_name(p.get(\"name\")) == target:\n",
    "                return p[\"id\"]\n",
    "        offset += limit\n",
    "        if offset >= payload.get(\"total\", 0): break\n",
    "    offset = 0\n",
    "    while True:\n",
    "        r = requests.get(PROJECTS_URL, headers=headers, params={\"offset\": offset, \"limit\": limit}, timeout=30)\n",
    "        r.raise_for_status(); payload = r.json()\n",
    "        for p in payload.get(\"projects\", []):\n",
    "            if target in _normalize_name(p.get(\"name\")):\n",
    "                return p[\"id\"]\n",
    "        offset += limit\n",
    "        if offset >= payload.get(\"total\", 0): break\n",
    "    return None\n",
    "\n",
    "def get_project(headers: dict, project_id: str) -> dict:\n",
    "    r = requests.get(GET_PROJECT_URL.format(project_id=project_id), headers=headers, timeout=30)\n",
    "    r.raise_for_status(); return r.json()\n",
    "\n",
    "def guess_dst_lang(headers: dict, project_id: str, default=\"fr-fr\") -> str:\n",
    "    info = get_project(headers, project_id)\n",
    "    return (info.get(\"dst_lang\") or info.get(\"dstLanguage\") or default)\n",
    "\n",
    "def select_project_id(selector: str) -> str:\n",
    "    return project_id_from_app_url(selector) or find_project_id_by_name(HEADERS, selector) or \\\n",
    "           (_ for _ in ()).throw(RuntimeError(f\"Aucun projet trouvé pour: {selector}\"))"
   ],
   "id": "f868f413016f609b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auth Rask OK.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T19:47:33.892136Z",
     "start_time": "2025-09-28T19:47:31.738809Z"
    }
   },
   "source": [
    "# (3) Ingestion + cibles (durée → mots via WPM)\n",
    "def _parse_timecode(tc) -> float:\n",
    "    if isinstance(tc, (int, float)): return float(tc)\n",
    "    s = str(tc).strip().replace(\",\", \".\")\n",
    "    m = re.match(r\"^(?P<h>\\d{1,2}):(?P<m>\\d{2}):(?P<s>\\d{2})(?:\\.(?P<ms>\\d{1,3}))?$\", s)\n",
    "    if m:\n",
    "        h = int(m.group(\"h\")); mn = int(m.group(\"m\")); sec = int(m.group(\"s\")); ms = int(m.group(\"ms\") or 0)\n",
    "        return h*3600 + mn*60 + sec + ms/1000.0\n",
    "    return float(s)\n",
    "\n",
    "WORD_RE = re.compile(r\"\\b[\\w’'-]+\\b\", flags=re.UNICODE)\n",
    "def words_count(text: str) -> int:\n",
    "    return len(WORD_RE.findall(text or \"\"))\n",
    "\n",
    "def words_target_for_duration(duration_sec: float, wpm: float) -> int:\n",
    "    return max(0, int(round(wpm * (duration_sec / 60.0))))\n",
    "\n",
    "def spoken_rate_wpm(words: int, duration_sec: float) -> float:\n",
    "    return (words / max(0.5, float(duration_sec))) * 60.0\n",
    "\n",
    "def get_transcription_df(headers: dict, project_id: str, wpm: float) -> pd.DataFrame:\n",
    "    r = requests.get(TRANSCRIPTION_URL.format(project_id=project_id), headers=headers, timeout=60)\n",
    "    r.raise_for_status(); data = r.json()\n",
    "    rows = []\n",
    "    for seg in data.get(\"segments\", []):\n",
    "        start = seg.get(\"start\"); end = seg.get(\"end\")\n",
    "        dur = max(0.0, _parse_timecode(end) - _parse_timecode(start))\n",
    "        src = (seg.get(\"src\") or {}).get(\"text\", \"\")\n",
    "        dst = (seg.get(\"dst\") or {}).get(\"text\", \"\")\n",
    "        rows.append({\n",
    "            \"segment_id\": seg.get(\"id\"),\n",
    "            \"speaker\": seg.get(\"speaker\"),\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"duration_sec\": round(dur, 3),\n",
    "            \"src_text\": src,\n",
    "            \"dst_text\": dst,\n",
    "            \"dst_length\": words_count(dst),\n",
    "            \"estimation_length\": words_target_for_duration(dur, wpm),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "project_id = select_project_id(PROJECT_SELECTOR)\n",
    "dst_lang = guess_dst_lang(HEADERS, project_id, default=LANG_DEST)\n",
    "df = get_transcription_df(HEADERS, project_id, WPM)\n",
    "indices_to_process = list(range(len(df))) if SEGMENTS_RANGE is None else list(SEGMENTS_RANGE)\n",
    "\n",
    "print(\"Project ID:\", project_id, \"| dst_lang:\", dst_lang, \"| segments:\", len(df))\n",
    "display(df.head(8)[[\"segment_id\",\"start\",\"end\",\"duration_sec\",\"dst_length\",\"estimation_length\",\"dst_text\"]])"
   ],
   "id": "1f349176d8b9e7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: bc8e6b7f-2ec4-4517-842d-fabf72ab9991 | dst_lang: fr-fr | segments: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                             segment_id         start           end  \\\n",
       "0  81f4de3f-c894-4472-a934-5a51d11a9f8d  00:00:00,857  00:00:07,597   \n",
       "1  6dd4b4fb-f4df-4092-be49-a874dfd76e1f  00:00:08,259  00:00:33,488   \n",
       "2  b1b46f6e-1e68-4c7a-a6e1-5eeaf9bc491d  00:00:34,847  00:01:09,457   \n",
       "3  dda51233-7321-4c5b-8a69-a10c187b2052  00:01:10,212  00:01:59,482   \n",
       "4  968ab399-20af-4cec-bf27-4b304be1bf53  00:02:02,640  00:02:47,936   \n",
       "5  68c0ca8b-fe05-4d5b-b365-7ed7c2ab86a8  00:02:49,074  00:03:34,779   \n",
       "6  803bb373-a69e-40e5-9c1c-78a833dbd000  00:03:35,305  00:03:38,640   \n",
       "\n",
       "   duration_sec  dst_length  estimation_length  \\\n",
       "0         6.740          19                 17   \n",
       "1        25.229          62                 62   \n",
       "2        34.610          58                 85   \n",
       "3        49.270          80                121   \n",
       "4        45.296         111                111   \n",
       "5        45.705         110                112   \n",
       "6         3.335          11                  8   \n",
       "\n",
       "                                            dst_text  \n",
       "0  Les mèches jouent un rôle crucial dans la comb...  \n",
       "1  La mèche en coton est un choix privilégié pour...  \n",
       "2  La mèche en bois fabriquée à partir de fines l...  \n",
       "3  Pour installer une mèche en coton commencez pa...  \n",
       "4  Pour la mèche en bois, il est essentiel de bie...  \n",
       "5  Ensuite, les mèches en coton sont souvent choi...  \n",
       "6  Choisir la bonne mèche est essentiel pour obte...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>dst_length</th>\n",
       "      <th>estimation_length</th>\n",
       "      <th>dst_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81f4de3f-c894-4472-a934-5a51d11a9f8d</td>\n",
       "      <td>00:00:00,857</td>\n",
       "      <td>00:00:07,597</td>\n",
       "      <td>6.740</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>Les mèches jouent un rôle crucial dans la comb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6dd4b4fb-f4df-4092-be49-a874dfd76e1f</td>\n",
       "      <td>00:00:08,259</td>\n",
       "      <td>00:00:33,488</td>\n",
       "      <td>25.229</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>La mèche en coton est un choix privilégié pour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b1b46f6e-1e68-4c7a-a6e1-5eeaf9bc491d</td>\n",
       "      <td>00:00:34,847</td>\n",
       "      <td>00:01:09,457</td>\n",
       "      <td>34.610</td>\n",
       "      <td>58</td>\n",
       "      <td>85</td>\n",
       "      <td>La mèche en bois fabriquée à partir de fines l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dda51233-7321-4c5b-8a69-a10c187b2052</td>\n",
       "      <td>00:01:10,212</td>\n",
       "      <td>00:01:59,482</td>\n",
       "      <td>49.270</td>\n",
       "      <td>80</td>\n",
       "      <td>121</td>\n",
       "      <td>Pour installer une mèche en coton commencez pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>968ab399-20af-4cec-bf27-4b304be1bf53</td>\n",
       "      <td>00:02:02,640</td>\n",
       "      <td>00:02:47,936</td>\n",
       "      <td>45.296</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>Pour la mèche en bois, il est essentiel de bie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68c0ca8b-fe05-4d5b-b365-7ed7c2ab86a8</td>\n",
       "      <td>00:02:49,074</td>\n",
       "      <td>00:03:34,779</td>\n",
       "      <td>45.705</td>\n",
       "      <td>110</td>\n",
       "      <td>112</td>\n",
       "      <td>Ensuite, les mèches en coton sont souvent choi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>803bb373-a69e-40e5-9c1c-78a833dbd000</td>\n",
       "      <td>00:03:35,305</td>\n",
       "      <td>00:03:38,640</td>\n",
       "      <td>3.335</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>Choisir la bonne mèche est essentiel pour obte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T19:47:33.934702Z",
     "start_time": "2025-09-28T19:47:33.920546Z"
    }
   },
   "source": [
    "# (4) Pack global — contraintes exactes + topic hints\n",
    "LEXICON = [\n",
    "    \"balance\", \"fondoir\", \"bain-marie\", \"cuillère en bois\", \"parfums\",\n",
    "    \"colorants\", \"mèches\", \"moules\", \"pastille métallique\", \"support de mèche\",\n",
    "    \"pipettes\", \"cire naturelle\"\n",
    "]\n",
    "\n",
    "TOPIC_HINTS = {\n",
    "    r\"abeille|abeilles\": \"cire d’abeille\",\n",
    "    r\"soja\": \"cire de soja\",\n",
    "    r\"paraffin\": \"cire de paraffine\",\n",
    "    r\"stéarique|stearique\": \"acide stéarique\",\n",
    "    r\"mèche|meche\": \"mèches\",\n",
    "    r\"moule|conten\": \"moules et contenants\",\n",
    "}\n",
    "\n",
    "def infer_topic(text: str) -> str:\n",
    "    s = (text or \"\").lower()\n",
    "    for pat, label in TOPIC_HINTS.items():\n",
    "        if re.search(pat, s):\n",
    "            return label\n",
    "    return \"présentation du matériel\"\n",
    "\n",
    "def build_segments_pack(df: pd.DataFrame, indices: list[int], tol: int = LENGTH_TOLERANCE) -> dict:\n",
    "    dfx = df.reset_index(drop=True)\n",
    "    pack = []\n",
    "    for i in indices:\n",
    "        base = str(dfx.at[i, \"dst_text\"] or dfx.at[i, \"src_text\"] or \"\").strip()\n",
    "        prev_text = str(dfx.at[i-1, \"dst_text\"]).strip() if i-1 >= 0 else \"\"\n",
    "        next_text = str(dfx.at[i+1, \"dst_text\"]).strip() if i+1 < len(dfx) else \"\"\n",
    "        tgt = int(dfx.at[i, \"estimation_length\"])\n",
    "        mn = max(1, tgt - tol); mx = tgt + tol\n",
    "        pack.append({\n",
    "            \"index\": i,\n",
    "            \"id\": str(dfx.at[i, \"segment_id\"]),\n",
    "            \"exact_words\": tgt,\n",
    "            \"min_words\": mn,\n",
    "            \"max_words\": mx,\n",
    "            \"duration_sec\": float(dfx.at[i, \"duration_sec\"]),\n",
    "            \"base_text\": base,\n",
    "            \"prev_text\": prev_text,\n",
    "            \"next_text\": next_text,\n",
    "            \"topic\": infer_topic(base)\n",
    "        })\n",
    "    context = {\n",
    "        \"language\": LANG_DEST,\n",
    "        \"lexicon_preferred\": LEXICON,\n",
    "        \"style\": \"présentation de matériel, pédagogique, clair, précis, ton professionnel sobre\",\n",
    "        \"audience\": \"débutant à intermédiaire\"\n",
    "    }\n",
    "    return {\"context\": context, \"segments\": pack}\n",
    "\n",
    "segments_pack = build_segments_pack(df, indices_to_process, tol=LENGTH_TOLERANCE)\n",
    "print(\"Pack prêt:\", len(segments_pack[\"segments\"]), \"segments\")"
   ],
   "id": "ff8bf456458850e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pack prêt: 7 segments\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T19:47:34.095742Z",
     "start_time": "2025-09-28T19:47:34.037084Z"
    }
   },
   "source": [
    "# (5) Client OpenAI + prompts pack/strict + parse JSON\n",
    "_openai_mode = None\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    _client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    _openai_mode = \"new\"\n",
    "except Exception:\n",
    "    try:\n",
    "        import openai\n",
    "        openai.api_key = OPENAI_API_KEY\n",
    "        _openai_mode = \"legacy\"\n",
    "    except Exception:\n",
    "        _openai_mode = None\n",
    "\n",
    "if not OPENAI_API_KEY or not _openai_mode:\n",
    "    print(\"AVERTISSEMENT: OpenAI indisponible. Fallback sur textes existants.\")\n",
    "\n",
    "GLOBAL_CHARTER = (\n",
    "    \"Génère tous les segments en une seule passe pour un style homogène. \"\n",
    "    \"Chaque segment est un paragraphe complet, indépendant, ponctué, ne se poursuit jamais dans le suivant. \"\n",
    "    \"Style pédagogique et précis, sans pas-à-pas; lexique constant: \" + \", \".join(LEXICON) + \".\"\n",
    ")\n",
    "\n",
    "BANNED_TAILS = {\"cet\",\"cette\",\"ceci\",\"cela\",\"ça\",\"ce\",\"les\",\"et\",\"mais\",\"ou\",\"donc\",\"ni\",\"car\",\"ainsi\"}\n",
    "\n",
    "def build_pack_prompt(lang_dest: str, pack: dict, smin: int, smax: int) -> list[dict]:\n",
    "    system = (\n",
    "        f\"Tu es un rédacteur pédagogique expert. Tu écris en {lang_dest}. \"\n",
    "        f\"{GLOBAL_CHARTER} Respecte des phrases courtes à moyennes. \"\n",
    "        \"Interdiction absolue de finir un segment par un démonstratif isolé (\\\"Cet\\\", \\\"Cela\\\", \\\"Ce\\\", etc.) ou par un connecteur. \"\n",
    "        \"RENVOIE UNIQUEMENT un JSON **valide** directement patchable par l'API Rask.\"\n",
    "    )\n",
    "    user_payload = {\n",
    "        \"contraintes_globales\": {\n",
    "            \"phrases\": f\"{smin}-{smax} mots/phrase environ\",\n",
    "            \"pas_d_actions\": True,\n",
    "            \"pas_de_listes\": True,\n",
    "            \"segment_independant\": True,\n",
    "            \"transition_douce\": True,\n",
    "            \"interdit_finir_par\": sorted(list(BANNED_TAILS))\n",
    "        },\n",
    "        \"règle_longueur\": (\n",
    "            \"Pour chaque segment, produire **exactement** <exact_words> mots lorsque possible; \"\n",
    "            \"tolérance de ±2 si la fluidité l'exige. Finir par une ponctuation terminale.\"\n",
    "        ),\n",
    "        \"segments\": [\n",
    "            {\n",
    "                \"id\": it[\"id\"],\n",
    "                \"exact_words\": it[\"exact_words\"],\n",
    "                \"min_words\": it[\"min_words\"],\n",
    "                \"max_words\": it[\"max_words\"],\n",
    "                \"duration_sec\": it[\"duration_sec\"],\n",
    "                \"base_text\": it[\"base_text\"],\n",
    "                \"prev_text\": it[\"prev_text\"],\n",
    "                \"next_text\": it[\"next_text\"],\n",
    "                \"topic\": it[\"topic\"]\n",
    "            } for it in pack[\"segments\"]\n",
    "        ],\n",
    "        \"sortie_json_patch_rask\": f'[[\"id\":\"<segment_id>\", \"dst\":{{\"text\":\"<texte exact>\", \"lang\":\"{LANG_DEST}\"}}]]'\n",
    "    }\n",
    "    return [{\"role\":\"system\",\"content\":system},\n",
    "            {\"role\":\"user\",\"content\":json.dumps(user_payload, ensure_ascii=False)}]\n",
    "\n",
    "def build_strict_segment_prompt(lang_dest: str, base_text: str, prev_text: str, next_text: str,\n",
    "                                exact_words: int, smin: int, smax: int) -> list[dict]:\n",
    "    system = (\n",
    "        f\"Tu écris en {lang_dest} un segment unique, très fluide et pédagogique. \"\n",
    "        f\"Un seul paragraphe. **EXACTEMENT {exact_words} mots** (compte standard). \"\n",
    "        \"Ponctuation finale obligatoire. Pas de listes ni d'actions procédurales. \"\n",
    "        \"Interdiction de finir par un démonstratif isolé ou un connecteur.\"\n",
    "    )\n",
    "    user = {\n",
    "        \"exact_words\": exact_words,\n",
    "        \"phrases\": f\"{smin}-{smax} mots/phrase environ\",\n",
    "        \"contexte\": {\"prev_text\": prev_text, \"next_text\": next_text},\n",
    "        \"base_text\": base_text,\n",
    "        \"sortie\": {\"format\": \"texte seul, sans guillemets, sans balises\"}\n",
    "    }\n",
    "    return [{\"role\":\"system\",\"content\":system},\n",
    "            {\"role\":\"user\",\"content\":json.dumps(user, ensure_ascii=False)}]\n",
    "\n",
    "def openai_chat(messages: list[dict], model: str, temperature: float) -> str:\n",
    "    last_err = None\n",
    "    for _ in range(1 + OPENAI_MAX_RETRIES):\n",
    "        try:\n",
    "            if _openai_mode == \"new\":\n",
    "                resp = _client.chat.completions.create(model=model, temperature=temperature, messages=messages)\n",
    "                return resp.choices[0].message.content.strip()\n",
    "            else:\n",
    "                resp = openai.ChatCompletion.create(model=model, temperature=temperature, messages=messages)\n",
    "                return resp[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        except Exception as e:\n",
    "            last_err = e; time.sleep(0.8)\n",
    "    raise RuntimeError(f\"Echec OpenAI après retries: {last_err}\")\n",
    "\n",
    "def parse_patch_json(raw: str) -> list[dict]:\n",
    "    try:\n",
    "        data = json.loads(raw)\n",
    "        if isinstance(data, dict) and \"segments\" in data: return data[\"segments\"]\n",
    "        if isinstance(data, list): return data\n",
    "    except json.JSONDecodeError:\n",
    "        m = re.search(r\"```json\\s*(\\[.*?\\])\\s*```\", raw, flags=re.DOTALL)\n",
    "        if m: return json.loads(m.group(1))\n",
    "        m2 = re.search(r\"(\\[\\s*\\{.*\\}\\s*\\])\", raw, flags=re.DOTALL)\n",
    "        if m2: return json.loads(m2.group(1))\n",
    "    raise RuntimeError(\"Réponse LLM non JSON patchable Rask.\")"
   ],
   "id": "6368114b17ea189a",
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T19:47:34.144107Z",
     "start_time": "2025-09-28T19:47:34.121260Z"
    }
   },
   "source": [
    "# (6) Post-traitements robustes — anti 'Cet.' + fins/débuts propres\n",
    "TERM_PUNCT_RE = re.compile(r\"[.!?…]$\")\n",
    "WEAK_START_RE = re.compile(r\"^(?:et|mais|ou|donc|or|ni|car|cela|les|ce|cet|cette|ceci|ça)\\b\", re.IGNORECASE)\n",
    "ORPHAN_END_RE = re.compile(r\"\\b(?:et|mais|ou|donc|or|ni|car|cela|les|ce|cet|cette|ceci|ça)\\s*$\", re.IGNORECASE)\n",
    "\n",
    "def fix_common_content_glitches(text: str) -> str:\n",
    "    s = (text or \"\").strip()\n",
    "    s = re.sub(r\"\\b100\\s*naturelle\\b\", \"100 % naturelle\", s)\n",
    "    s = re.sub(r\"\\s{2,}\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def ensure_terminal_punct(text: str) -> str:\n",
    "    s = (text or \"\").strip()\n",
    "    s = ORPHAN_END_RE.sub(\"\", s).strip()\n",
    "    if not TERM_PUNCT_RE.search(s):\n",
    "        s += \".\"\n",
    "    return s\n",
    "\n",
    "def sanitize_end_tail(text: str) -> str:\n",
    "    s = (text or \"\").strip()\n",
    "    # Supprime un éventuel dernier mot interdit\n",
    "    toks = WORD_RE.findall(s)\n",
    "    if not toks: return s\n",
    "    last = toks[-1].lower()\n",
    "    if last in BANNED_TAILS:\n",
    "        # retire le dernier mot et toute fin non ponctuée\n",
    "        s = re.sub(r\"\\b\" + re.escape(toks[-1]) + r\"[\\W]*$\", \"\", s).strip()\n",
    "    s = ensure_terminal_punct(s)\n",
    "    return s\n",
    "\n",
    "def sanitize_start(text: str) -> str:\n",
    "    s = (text or \"\").strip()\n",
    "    if WEAK_START_RE.match(s):\n",
    "        s = WEAK_START_RE.sub(\"Ensuite,\", s, count=1)\n",
    "        s = re.sub(r\"\\s{2,}\", \" \", s).strip()\n",
    "        if s: s = s[0].upper() + s[1:]\n",
    "    return s\n",
    "\n",
    "# Banque de micro-phrases complètes (pas de 'Cet.') pour extension douce\n",
    "FILLER_BANK = [\n",
    "    \"Ce point servira de repère.\",                   # 5 mots\n",
    "    \"Ce repère facilite vos choix.\",                # 5\n",
    "    \"Ces bases guideront la suite.\",               # 5\n",
    "    \"La suite détaillera ces critères.\",           # 5\n",
    "    \"Ce résumé fixe l'essentiel.\",                 # 5 (\"l'essentiel\" = 1 mot)\n",
    "    \"Vous disposez maintenant d'un cadre clair.\",  # 7\n",
    "    \"Ces repères soutiennent votre progression.\",  # 5\n",
    "    \"Retenez surtout la logique de sélection.\",    # 6\n",
    "    \"Ceci clarifie l'objectif pédagogique.\",       # 5\n",
    "    \"Le prochain point prolonge cette idée.\",      # 6\n",
    "]\n",
    "\n",
    "def choose_fillers_to_reach(diff: int) -> list[str]:\n",
    "    # Petite DP gloutonne + amélioration simple pour couvrir diff\n",
    "    # Pré-calcul des longueurs\n",
    "    lengths = [words_count(s) for s in FILLER_BANK]\n",
    "    items = list(zip(FILLER_BANK, lengths))\n",
    "    # Glouton décroissant\n",
    "    items.sort(key=lambda x: x[1], reverse=True)\n",
    "    out = []\n",
    "    remain = diff\n",
    "    for sent, ln in items:\n",
    "        while remain - ln >= 0 and remain > 0:\n",
    "            out.append(sent); remain -= ln\n",
    "            if remain == 0: return out\n",
    "    # Si on n'est pas à zéro, on tente une seconde passe fine\n",
    "    if remain > 0:\n",
    "        # essayer toutes petites combinaisons jusqu'à 2 phrases\n",
    "        for i, (s1,l1) in enumerate(items):\n",
    "            if l1 == remain: return [s1]\n",
    "            for s2,l2 in items[i:]:\n",
    "                if l1 + l2 == remain: return [s1,s2]\n",
    "    return out  # peut être vide; on gèrera plus tard\n",
    "\n",
    "def trim_to_exact_words(text: str, target: int) -> str:\n",
    "    # Coupe avec respect phrase → mots; évite de finir sur un démonstratif\n",
    "    s = fix_common_content_glitches(text)\n",
    "    toks = WORD_RE.findall(s)\n",
    "    if len(toks) <= target:\n",
    "        return s\n",
    "    # Tente de couper au dernier séparateur de phrase\n",
    "    parts = re.split(r\"(?<=[.!?…])\\s+\", s)\n",
    "    acc = []\n",
    "    for p in parts:\n",
    "        if words_count(\" \".join(acc + [p])) <= target:\n",
    "            acc.append(p)\n",
    "        else:\n",
    "            break\n",
    "    s2 = \" \".join(acc).strip()\n",
    "    if words_count(s2) > target:\n",
    "        # fallback: couper au mot\n",
    "        sub = toks[:target]\n",
    "        s2 = \" \".join(sub)\n",
    "    s2 = sanitize_end_tail(s2)\n",
    "    return s2\n",
    "\n",
    "def expand_to_exact_words(text: str, target: int) -> str:\n",
    "    s = fix_common_content_glitches(text)\n",
    "    cur = words_count(s)\n",
    "    if cur >= target:\n",
    "        return s\n",
    "    need = target - cur\n",
    "    fillers = choose_fillers_to_reach(need)\n",
    "    if fillers:\n",
    "        s2 = (s + \" \" + \" \".join(fillers)).strip()\n",
    "        if words_count(s2) == target:\n",
    "            return ensure_terminal_punct(sanitize_end_tail(s2))\n",
    "    # Dernier recours: répéter une phrase neutre pour approcher, puis rogner proprement\n",
    "    pad = \" Ce résumé fixe l'essentiel.\"\n",
    "    while words_count(s) + words_count(pad) <= target:\n",
    "        s += pad\n",
    "    if words_count(s) < target:\n",
    "        s += \" Cette précision complète l'ensemble.\"  # 5 mots environ\n",
    "    s = trim_to_exact_words(s, target)\n",
    "    return ensure_terminal_punct(sanitize_end_tail(s))\n",
    "\n",
    "def postprocess_segment(text: str, target_words: int, fix_start: bool = True) -> str:\n",
    "    s = (text or \"\").strip()\n",
    "    s = fix_common_content_glitches(s)\n",
    "    # Ajuster à EXACT\n",
    "    wc = words_count(s)\n",
    "    if wc > target_words:\n",
    "        s = trim_to_exact_words(s, target_words)\n",
    "    elif wc < target_words:\n",
    "        s = expand_to_exact_words(s, target_words)\n",
    "    # Fins et débuts propres\n",
    "    s = sanitize_end_tail(ensure_terminal_punct(s))\n",
    "    if fix_start:\n",
    "        s = sanitize_start(s)\n",
    "    # Double-check exact\n",
    "    if words_count(s) != target_words:\n",
    "        # ajustement final minimal: rogner/étendre proprement\n",
    "        if words_count(s) > target_words:\n",
    "            s = trim_to_exact_words(s, target_words)\n",
    "        else:\n",
    "            s = expand_to_exact_words(s, target_words)\n",
    "    return s"
   ],
   "id": "46797850d14a1ad2",
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T19:49:59.261613Z",
     "start_time": "2025-09-28T19:47:34.166837Z"
    }
   },
   "source": [
    "# (7) Génération pack + régénération + normalisation EXACT (LLM d'abord, algo sinon)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def generate_pack(df: pd.DataFrame,\n",
    "                  lang_dest: str,\n",
    "                  indices: list[int],\n",
    "                  tol_words: int,\n",
    "                  smin: int, smax: int,\n",
    "                  model: str = OPENAI_MODEL,\n",
    "                  temperature: float = OPENAI_TEMPERATURE) -> pd.DataFrame:\n",
    "    dfx = df.reset_index(drop=True).copy()\n",
    "    pack = build_segments_pack(dfx, indices, tol=tol_words)\n",
    "\n",
    "    # Pass 1 — pack\n",
    "    if not OPENAI_API_KEY or _openai_mode is None:\n",
    "        print(\"OpenAI indisponible: fallback base_text.\")\n",
    "        results = [{\"id\": it[\"id\"], \"dst\": {\"text\": it[\"base_text\"], \"lang\": lang_dest}} for it in pack[\"segments\"]]\n",
    "    else:\n",
    "        msgs = build_pack_prompt(lang_dest, pack, smin=smin, smax=smax)\n",
    "        raw = openai_chat(msgs, model=model, temperature=temperature)\n",
    "        results = parse_patch_json(raw)\n",
    "\n",
    "    # Injection brute\n",
    "    if \"new_text\" not in dfx.columns: dfx[\"new_text\"] = pd.NA\n",
    "    if \"new_length\" not in dfx.columns: dfx[\"new_length\"] = pd.NA\n",
    "    sid_to_idx = {str(dfx.at[i,\"segment_id\"]): i for i in range(len(dfx))}\n",
    "    for item in results:\n",
    "        sid = item.get(\"id\") or item.get(\"segment_id\")\n",
    "        txt = (item.get(\"dst\",{}).get(\"text\") or item.get(\"text\") or \"\").strip()\n",
    "        if sid in sid_to_idx:\n",
    "            j = sid_to_idx[sid]\n",
    "            dfx.at[j,\"new_text\"] = txt\n",
    "            dfx.at[j,\"new_length\"] = words_count(txt)\n",
    "\n",
    "    # Normalisation EXACT via LLM strict, sinon fallback algo\n",
    "    for i in indices:\n",
    "        target = int(dfx.at[i,\"estimation_length\"])\n",
    "        base = str(dfx.at[i,\"new_text\"] or dfx.at[i,\"dst_text\"] or dfx.at[i,\"src_text\"] or \"\").strip()\n",
    "        prev_text = str(dfx.at[i-1,\"new_text\"] or dfx.at[i-1,\"dst_text\"] or \"\").strip() if i-1 >= 0 else \"\"\n",
    "        next_text = str(dfx.at[i+1,\"new_text\"] or dfx.at[i+1,\"dst_text\"] or \"\").strip() if i+1 < len(dfx) else \"\"\n",
    "        # LLM strict\n",
    "        ok = False\n",
    "        if OPENAI_API_KEY and _openai_mode:\n",
    "            for _ in range(STRICT_MAX_RETRIES):\n",
    "                msgs = build_strict_segment_prompt(LANG_DEST, base, prev_text, next_text, target, smin, smax)\n",
    "                cand = openai_chat(msgs, model=model, temperature=temperature).strip()\n",
    "                cand = sanitize_start(sanitize_end_tail(ensure_terminal_punct(cand)))\n",
    "                if words_count(cand) == target and not ORPHAN_END_RE.search(cand):\n",
    "                    dfx.at[i,\"new_text\"] = cand\n",
    "                    dfx.at[i,\"new_length\"] = target\n",
    "                    ok = True\n",
    "                    break\n",
    "        if not ok:\n",
    "            # Fallback algo exact\n",
    "            repaired = postprocess_segment(base, target_words=target, fix_start=True)\n",
    "            dfx.at[i,\"new_text\"] = repaired\n",
    "            dfx.at[i,\"new_length\"] = words_count(repaired)\n",
    "\n",
    "    return dfx\n",
    "\n",
    "df = generate_pack(df, LANG_DEST, indices_to_process, tol_words=LENGTH_TOLERANCE,\n",
    "                   smin=MIN_SENT_WORDS, smax=MAX_SENT_WORDS)\n",
    "print(\"Génération + normalisation terminées.\")"
   ],
   "id": "25ca44aab9193cd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération + normalisation terminées.\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T19:49:59.375662Z",
     "start_time": "2025-09-28T19:49:59.344264Z"
    }
   },
   "source": [
    "# (8) Audit frontières + auto-fix final\n",
    "def sentence_tokens(text: str) -> list[str]:\n",
    "    s = (text or \"\").strip()\n",
    "    if not s: return []\n",
    "    parts = re.split(r\"(?<=[.!?…])\\s+\", s)\n",
    "    return [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "def audit_boundaries(df: pd.DataFrame, indices: list[int], smin: int, smax: int) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for i in indices:\n",
    "        txt = (df.at[i,\"new_text\"] or \"\").strip()\n",
    "        sins = sentence_tokens(txt)\n",
    "        issues = []\n",
    "        if not TERM_PUNCT_RE.search(txt): issues.append(\"no_terminal_punct\")\n",
    "        if ORPHAN_END_RE.search(txt): issues.append(\"orphan_connector_end\")\n",
    "        if i+1 < len(df):\n",
    "            nxt = (df.at[i+1,\"new_text\"] or \"\").strip()\n",
    "            if WEAK_START_RE.search(nxt): issues.append(\"weak_start_next\")\n",
    "        if len(sins) == 0: issues.append(\"empty_segment\")\n",
    "        if len(sins) > 4: issues.append(\"too_many_sentences\")\n",
    "        for s in sins:\n",
    "            wc = words_count(s)\n",
    "            if wc < smin: issues.append(\"sentence_too_short\")\n",
    "            if wc > smax: issues.append(\"sentence_too_long\")\n",
    "        if issues:\n",
    "            rows.append({\"index\": i, \"segment_id\": df.at[i,\"segment_id\"], \"issues\": \", \".join(sorted(set(issues)))})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def auto_fix_boundaries(df: pd.DataFrame, indices: list[int]) -> pd.DataFrame:\n",
    "    dfx = df.copy()\n",
    "    for i in indices:\n",
    "        s = (dfx.at[i,\"new_text\"] or \"\").strip()\n",
    "        s = sanitize_end_tail(ensure_terminal_punct(s))\n",
    "        dfx.at[i,\"new_text\"] = s\n",
    "        dfx.at[i,\"new_length\"] = words_count(s)\n",
    "        if i+1 < len(dfx):\n",
    "            nxt = (dfx.at[i+1,\"new_text\"] or \"\").strip()\n",
    "            nxt = sanitize_start(nxt)\n",
    "            dfx.at[i+1,\"new_text\"] = nxt\n",
    "            dfx.at[i+1,\"new_length\"] = words_count(nxt)\n",
    "    return dfx\n",
    "\n",
    "issues_df = audit_boundaries(df, indices_to_process, smin=MIN_SENT_WORDS, smax=MAX_SENT_WORDS)\n",
    "print(\"Issues frontières détectées:\", len(issues_df))\n",
    "display(issues_df.head(20))\n",
    "\n",
    "df = auto_fix_boundaries(df, indices_to_process)\n",
    "\n",
    "issues_after = audit_boundaries(df, indices_to_process, smin=MIN_SENT_WORDS, smax=MAX_SENT_WORDS)\n",
    "print(\"Issues restantes après fix:\", len(issues_after))\n",
    "display(issues_after.head(20))"
   ],
   "id": "b4099c0104d97f38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues frontières détectées: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   index                            segment_id  \\\n",
       "0      1  6dd4b4fb-f4df-4092-be49-a874dfd76e1f   \n",
       "1      2  b1b46f6e-1e68-4c7a-a6e1-5eeaf9bc491d   \n",
       "2      3  dda51233-7321-4c5b-8a69-a10c187b2052   \n",
       "3      4  968ab399-20af-4cec-bf27-4b304be1bf53   \n",
       "4      5  68c0ca8b-fe05-4d5b-b365-7ed7c2ab86a8   \n",
       "\n",
       "                                              issues  \n",
       "0                                  sentence_too_long  \n",
       "1  sentence_too_long, sentence_too_short, too_man...  \n",
       "2  sentence_too_long, sentence_too_short, too_man...  \n",
       "3              sentence_too_long, too_many_sentences  \n",
       "4                                  sentence_too_long  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6dd4b4fb-f4df-4092-be49-a874dfd76e1f</td>\n",
       "      <td>sentence_too_long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b1b46f6e-1e68-4c7a-a6e1-5eeaf9bc491d</td>\n",
       "      <td>sentence_too_long, sentence_too_short, too_man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>dda51233-7321-4c5b-8a69-a10c187b2052</td>\n",
       "      <td>sentence_too_long, sentence_too_short, too_man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>968ab399-20af-4cec-bf27-4b304be1bf53</td>\n",
       "      <td>sentence_too_long, too_many_sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>68c0ca8b-fe05-4d5b-b365-7ed7c2ab86a8</td>\n",
       "      <td>sentence_too_long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues restantes après fix: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   index                            segment_id  \\\n",
       "0      1  6dd4b4fb-f4df-4092-be49-a874dfd76e1f   \n",
       "1      2  b1b46f6e-1e68-4c7a-a6e1-5eeaf9bc491d   \n",
       "2      3  dda51233-7321-4c5b-8a69-a10c187b2052   \n",
       "3      4  968ab399-20af-4cec-bf27-4b304be1bf53   \n",
       "4      5  68c0ca8b-fe05-4d5b-b365-7ed7c2ab86a8   \n",
       "\n",
       "                                              issues  \n",
       "0                                  sentence_too_long  \n",
       "1  sentence_too_long, sentence_too_short, too_man...  \n",
       "2  sentence_too_long, sentence_too_short, too_man...  \n",
       "3              sentence_too_long, too_many_sentences  \n",
       "4                                  sentence_too_long  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6dd4b4fb-f4df-4092-be49-a874dfd76e1f</td>\n",
       "      <td>sentence_too_long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b1b46f6e-1e68-4c7a-a6e1-5eeaf9bc491d</td>\n",
       "      <td>sentence_too_long, sentence_too_short, too_man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>dda51233-7321-4c5b-8a69-a10c187b2052</td>\n",
       "      <td>sentence_too_long, sentence_too_short, too_man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>968ab399-20af-4cec-bf27-4b304be1bf53</td>\n",
       "      <td>sentence_too_long, too_many_sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>68c0ca8b-fe05-4d5b-b365-7ed7c2ab86a8</td>\n",
       "      <td>sentence_too_long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T19:49:59.446163Z",
     "start_time": "2025-09-28T19:49:59.419795Z"
    }
   },
   "source": [
    "# (9) Visualisation AVANT / APRÈS + tailles\n",
    "view_cols = [\n",
    "    \"segment_id\",\"start\",\"end\",\"duration_sec\",\"estimation_length\",\n",
    "    \"dst_text\",\"dst_length\",\"new_text\",\"new_length\"\n",
    "]\n",
    "table = df.loc[indices_to_process, view_cols].copy()\n",
    "display(table.head(20))\n",
    "table.to_csv(\"v5_pack_avant_apres.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Export -> v5_pack_avant_apres.csv\")"
   ],
   "id": "9e567b6ef4b1f174",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             segment_id         start           end  \\\n",
       "0  81f4de3f-c894-4472-a934-5a51d11a9f8d  00:00:00,857  00:00:07,597   \n",
       "1  6dd4b4fb-f4df-4092-be49-a874dfd76e1f  00:00:08,259  00:00:33,488   \n",
       "2  b1b46f6e-1e68-4c7a-a6e1-5eeaf9bc491d  00:00:34,847  00:01:09,457   \n",
       "3  dda51233-7321-4c5b-8a69-a10c187b2052  00:01:10,212  00:01:59,482   \n",
       "4  968ab399-20af-4cec-bf27-4b304be1bf53  00:02:02,640  00:02:47,936   \n",
       "5  68c0ca8b-fe05-4d5b-b365-7ed7c2ab86a8  00:02:49,074  00:03:34,779   \n",
       "6  803bb373-a69e-40e5-9c1c-78a833dbd000  00:03:35,305  00:03:38,640   \n",
       "\n",
       "   duration_sec  estimation_length  \\\n",
       "0         6.740                 17   \n",
       "1        25.229                 62   \n",
       "2        34.610                 85   \n",
       "3        49.270                121   \n",
       "4        45.296                111   \n",
       "5        45.705                112   \n",
       "6         3.335                  8   \n",
       "\n",
       "                                            dst_text  dst_length  \\\n",
       "0  Les mèches jouent un rôle crucial dans la comb...          19   \n",
       "1  La mèche en coton est un choix privilégié pour...          62   \n",
       "2  La mèche en bois fabriquée à partir de fines l...          58   \n",
       "3  Pour installer une mèche en coton commencez pa...          80   \n",
       "4  Pour la mèche en bois, il est essentiel de bie...         111   \n",
       "5  Ensuite, les mèches en coton sont souvent choi...         110   \n",
       "6  Choisir la bonne mèche est essentiel pour obte...          11   \n",
       "\n",
       "                                            new_text new_length  \n",
       "0  Ensuite, mèches influencent significativement ...         17  \n",
       "1  La mèche en coton est souvent choisie pour sa ...         62  \n",
       "2  La mèche en bois fabriquée à partir de fines l...         82  \n",
       "3  Pour installer une mèche en coton commencez pa...        121  \n",
       "4  Pour la mèche en bois, il est essentiel de bie...        111  \n",
       "5  Ensuite, les mèches en coton sont souvent choi...        110  \n",
       "6  Choisir la bonne mèche garantit une bougie réu...          8  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>estimation_length</th>\n",
       "      <th>dst_text</th>\n",
       "      <th>dst_length</th>\n",
       "      <th>new_text</th>\n",
       "      <th>new_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81f4de3f-c894-4472-a934-5a51d11a9f8d</td>\n",
       "      <td>00:00:00,857</td>\n",
       "      <td>00:00:07,597</td>\n",
       "      <td>6.740</td>\n",
       "      <td>17</td>\n",
       "      <td>Les mèches jouent un rôle crucial dans la comb...</td>\n",
       "      <td>19</td>\n",
       "      <td>Ensuite, mèches influencent significativement ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6dd4b4fb-f4df-4092-be49-a874dfd76e1f</td>\n",
       "      <td>00:00:08,259</td>\n",
       "      <td>00:00:33,488</td>\n",
       "      <td>25.229</td>\n",
       "      <td>62</td>\n",
       "      <td>La mèche en coton est un choix privilégié pour...</td>\n",
       "      <td>62</td>\n",
       "      <td>La mèche en coton est souvent choisie pour sa ...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b1b46f6e-1e68-4c7a-a6e1-5eeaf9bc491d</td>\n",
       "      <td>00:00:34,847</td>\n",
       "      <td>00:01:09,457</td>\n",
       "      <td>34.610</td>\n",
       "      <td>85</td>\n",
       "      <td>La mèche en bois fabriquée à partir de fines l...</td>\n",
       "      <td>58</td>\n",
       "      <td>La mèche en bois fabriquée à partir de fines l...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dda51233-7321-4c5b-8a69-a10c187b2052</td>\n",
       "      <td>00:01:10,212</td>\n",
       "      <td>00:01:59,482</td>\n",
       "      <td>49.270</td>\n",
       "      <td>121</td>\n",
       "      <td>Pour installer une mèche en coton commencez pa...</td>\n",
       "      <td>80</td>\n",
       "      <td>Pour installer une mèche en coton commencez pa...</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>968ab399-20af-4cec-bf27-4b304be1bf53</td>\n",
       "      <td>00:02:02,640</td>\n",
       "      <td>00:02:47,936</td>\n",
       "      <td>45.296</td>\n",
       "      <td>111</td>\n",
       "      <td>Pour la mèche en bois, il est essentiel de bie...</td>\n",
       "      <td>111</td>\n",
       "      <td>Pour la mèche en bois, il est essentiel de bie...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68c0ca8b-fe05-4d5b-b365-7ed7c2ab86a8</td>\n",
       "      <td>00:02:49,074</td>\n",
       "      <td>00:03:34,779</td>\n",
       "      <td>45.705</td>\n",
       "      <td>112</td>\n",
       "      <td>Ensuite, les mèches en coton sont souvent choi...</td>\n",
       "      <td>110</td>\n",
       "      <td>Ensuite, les mèches en coton sont souvent choi...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>803bb373-a69e-40e5-9c1c-78a833dbd000</td>\n",
       "      <td>00:03:35,305</td>\n",
       "      <td>00:03:38,640</td>\n",
       "      <td>3.335</td>\n",
       "      <td>8</td>\n",
       "      <td>Choisir la bonne mèche est essentiel pour obte...</td>\n",
       "      <td>11</td>\n",
       "      <td>Choisir la bonne mèche garantit une bougie réu...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export -> v5_pack_avant_apres.csv\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T19:49:59.598629Z",
     "start_time": "2025-09-28T19:49:59.571122Z"
    }
   },
   "source": [
    "# (10) Audit vitesse parlée (WPM) par segment + statut\n",
    "def rate_status(rate_wpm: float, target_wpm: float, tol_pct: float) -> str:\n",
    "    if target_wpm <= 0: return \"NA\"\n",
    "    delta_pct = 100.0 * (rate_wpm - target_wpm) / target_wpm\n",
    "    if abs(delta_pct) <= tol_pct:\n",
    "        return \"OK\"\n",
    "    return \"FAST\" if delta_pct > 0 else \"SLOW\"\n",
    "\n",
    "rate_rows = []\n",
    "for i in indices_to_process:\n",
    "    d = float(df.at[i,\"duration_sec\"] or 0.0)\n",
    "    w = int(df.at[i,\"new_length\"] or 0)\n",
    "    tgt = int(df.at[i,\"estimation_length\"] or 0)\n",
    "    rate = spoken_rate_wpm(w, d) if d > 0 else 0.0\n",
    "    status = rate_status(rate, WPM, RATE_TOL_PCT)\n",
    "    rate_rows.append({\n",
    "        \"segment_id\": df.at[i,\"segment_id\"],\n",
    "        \"duration_sec\": d,\n",
    "        \"target_words\": tgt,\n",
    "        \"new_length\": w,\n",
    "        \"rate_wpm\": round(rate, 1),\n",
    "        \"target_wpm\": WPM,\n",
    "        \"rate_deviation_pct\": round(100.0*(rate-WPM)/WPM, 1) if WPM > 0 else 0.0,\n",
    "        \"rate_status\": status\n",
    "    })\n",
    "rate_df = pd.DataFrame(rate_rows)\n",
    "display(rate_df.head(20))\n",
    "rate_df.to_csv(\"v5_audit_vitesse.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Export -> v5_audit_vitesse.csv\")"
   ],
   "id": "b4604ac0c076621f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             segment_id  duration_sec  target_words  \\\n",
       "0  81f4de3f-c894-4472-a934-5a51d11a9f8d         6.740            17   \n",
       "1  6dd4b4fb-f4df-4092-be49-a874dfd76e1f        25.229            62   \n",
       "2  b1b46f6e-1e68-4c7a-a6e1-5eeaf9bc491d        34.610            85   \n",
       "3  dda51233-7321-4c5b-8a69-a10c187b2052        49.270           121   \n",
       "4  968ab399-20af-4cec-bf27-4b304be1bf53        45.296           111   \n",
       "5  68c0ca8b-fe05-4d5b-b365-7ed7c2ab86a8        45.705           112   \n",
       "6  803bb373-a69e-40e5-9c1c-78a833dbd000         3.335             8   \n",
       "\n",
       "   new_length  rate_wpm  target_wpm  rate_deviation_pct rate_status  \n",
       "0          17     151.3       147.0                 2.9        FAST  \n",
       "1          62     147.4       147.0                 0.3          OK  \n",
       "2          82     142.2       147.0                -3.3        SLOW  \n",
       "3         121     147.4       147.0                 0.2          OK  \n",
       "4         111     147.0       147.0                 0.0          OK  \n",
       "5         110     144.4       147.0                -1.8          OK  \n",
       "6           8     143.9       147.0                -2.1        SLOW  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>target_words</th>\n",
       "      <th>new_length</th>\n",
       "      <th>rate_wpm</th>\n",
       "      <th>target_wpm</th>\n",
       "      <th>rate_deviation_pct</th>\n",
       "      <th>rate_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81f4de3f-c894-4472-a934-5a51d11a9f8d</td>\n",
       "      <td>6.740</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>151.3</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>FAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6dd4b4fb-f4df-4092-be49-a874dfd76e1f</td>\n",
       "      <td>25.229</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>147.4</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b1b46f6e-1e68-4c7a-a6e1-5eeaf9bc491d</td>\n",
       "      <td>34.610</td>\n",
       "      <td>85</td>\n",
       "      <td>82</td>\n",
       "      <td>142.2</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>SLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dda51233-7321-4c5b-8a69-a10c187b2052</td>\n",
       "      <td>49.270</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>147.4</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>968ab399-20af-4cec-bf27-4b304be1bf53</td>\n",
       "      <td>45.296</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>147.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68c0ca8b-fe05-4d5b-b365-7ed7c2ab86a8</td>\n",
       "      <td>45.705</td>\n",
       "      <td>112</td>\n",
       "      <td>110</td>\n",
       "      <td>144.4</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>803bb373-a69e-40e5-9c1c-78a833dbd000</td>\n",
       "      <td>3.335</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>143.9</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>SLOW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export -> v5_audit_vitesse.csv\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T19:50:01.016067Z",
     "start_time": "2025-09-28T19:49:59.719849Z"
    }
   },
   "source": [
    "# (11) Préparation payload & patch Rask (dry‑run par défaut)\n",
    "def _row_to_segment_patch(row: pd.Series, dst_lang: str, include_timing: bool = False) -> dict:\n",
    "    seg = {\"id\": str(row[\"segment_id\"]), \"dst\": {\"text\": str(row[\"new_text\"]), \"lang\": dst_lang}}\n",
    "    if include_timing:\n",
    "        if pd.notna(row.get(\"start\")): seg[\"start\"] = str(row[\"start\"])\n",
    "        if pd.notna(row.get(\"end\")):   seg[\"end\"]   = str(row[\"end\"])\n",
    "    return seg\n",
    "\n",
    "def build_segments_payload_for_patch(df: pd.DataFrame,\n",
    "                                     dst_lang: str,\n",
    "                                     indices: list[int],\n",
    "                                     include_timing: bool = False) -> list[dict]:\n",
    "    subset = df.loc[indices]\n",
    "    subset = subset[subset[\"new_text\"].notna() & (subset[\"new_text\"].astype(str).str.strip().str.len() > 0)]\n",
    "    return [_row_to_segment_patch(row, dst_lang, include_timing=include_timing) for _, row in subset.iterrows()]\n",
    "\n",
    "def patch_segments_text(headers: dict,\n",
    "                        project_id: str,\n",
    "                        segments: list[dict],\n",
    "                        batch_size: int = 100,\n",
    "                        dry_run: bool = True,\n",
    "                        sleep_between: float = 0.4) -> None:\n",
    "    url = PATCH_SEGMENTS_URL.format(project_id=project_id)\n",
    "    total = len(segments); batches = math.ceil(total / batch_size)\n",
    "    for b in range(batches):\n",
    "        chunk = segments[b*batch_size:(b+1)*batch_size]\n",
    "        if dry_run:\n",
    "            print(f\"[DRY-RUN] PATCH {b+1}/{batches} -> {url} ({len(chunk)} segments)\")\n",
    "            preview = [{\"id\": s[\"id\"],\n",
    "                        \"dst_len\": len(str(s.get(\"dst\",{}).get(\"text\",\"\"))).__int__(),\n",
    "                        \"dst_lang\": s[\"dst\"].get(\"lang\"),\n",
    "                        \"start\": s.get(\"start\"), \"end\": s.get(\"end\")} for s in chunk]\n",
    "            display(pd.DataFrame(preview))\n",
    "            continue\n",
    "    \n",
    "        resp = requests.patch(url, headers={**headers,\"Content-Type\":\"application/json\"},\n",
    "                              json={\"segments\": chunk}, timeout=60)\n",
    "        if resp.status_code >= 400:\n",
    "            try: print(\"Erreur serveur:\", json.dumps(resp.json(), ensure_ascii=False, indent=2))\n",
    "            except Exception: print(\"Erreur brute:\", resp.text)\n",
    "            resp.raise_for_status()\n",
    "        print(f\"OK PATCH {b+1}/{batches}: {len(chunk)} segments\")\n",
    "        time.sleep(sleep_between)\n",
    "\n",
    "payload = build_segments_payload_for_patch(df, dst_lang=dst_lang, indices=indices_to_process, include_timing=INCLUDE_TIMING)\n",
    "print(\"Segments à patcher:\", len(payload))\n",
    "patch_segments_text(HEADERS, project_id, payload, dry_run=DRY_RUN)"
   ],
   "id": "24d292fc7aacae7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segments à patcher: 7\n",
      "OK PATCH 1/1: 7 segments\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T19:50:01.046642Z",
     "start_time": "2025-09-28T19:50:01.040011Z"
    }
   },
   "source": [
    "# (12) Sanitiser un payload JSON EXISTANT (répare 'Cet.' & phrases inachevées)\n",
    "def sanitize_existing_payload(payload: list[dict], wpm: float = WPM) -> list[dict]:\n",
    "    out = []\n",
    "    for item in payload:\n",
    "        seg_id = item.get(\"id\") or item.get(\"segment_id\")\n",
    "        start = item.get(\"start\"); end = item.get(\"end\")\n",
    "        txt = (item.get(\"dst\",{}).get(\"text\") or item.get(\"text\") or \"\").strip()\n",
    "        dur = 0.0\n",
    "        try:\n",
    "            if start and end:\n",
    "                dur = max(0.0, _parse_timecode(end) - _parse_timecode(start))\n",
    "        except Exception:\n",
    "            dur = 0.0\n",
    "        target = words_target_for_duration(dur, wpm) if dur > 0 else words_count(txt)\n",
    "        fixed = postprocess_segment(txt, target_words=target, fix_start=True)\n",
    "        out.append({\n",
    "            \"id\": seg_id,\n",
    "            \"dst\": {\"text\": fixed, \"lang\": item.get(\"dst\",{}).get(\"lang\",\"fr-fr\")},\n",
    "            \"start\": start, \"end\": end\n",
    "        })\n",
    "    return out\n",
    "\n",
    "# Exemple d'utilisation:\n",
    "example_payload = [\n",
    "  {\n",
    "    \"id\": \"342b2806-3672-4035-8971-548b78a169f0\",\n",
    "    \"dst\": {\"text\": \"Considérée comme 100 naturelle elle est sans danger pour tous Cet.\", \"lang\": \"fr-fr\"},\n",
    "    \"start\": \"00:00:30,823\", \"end\": \"00:00:35,186\"\n",
    "  }\n",
    "]\n",
    "sanitized = sanitize_existing_payload(example_payload, wpm=WPM)\n",
    "print(\"Payload réparé (extrait):\\n\", json.dumps(sanitized, ensure_ascii=False, indent=2))"
   ],
   "id": "1a4d84900679daed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload réparé (extrait):\n",
      " [\n",
      "  {\n",
      "    \"id\": \"342b2806-3672-4035-8971-548b78a169f0\",\n",
      "    \"dst\": {\n",
      "      \"text\": \"Considérée comme 100 % naturelle elle est sans danger pour tous.\",\n",
      "      \"lang\": \"fr-fr\"\n",
      "    },\n",
      "    \"start\": \"00:00:30,823\",\n",
      "    \"end\": \"00:00:35,186\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T19:50:01.104693Z",
     "start_time": "2025-09-28T19:50:01.089386Z"
    }
   },
   "source": [
    "# (13) Exports finaux\n",
    "path_dir_output = os.path.join(os.getcwd(), PROJECT_SELECTOR)\n",
    "os.makedirs(path_dir_output, exist_ok=True)\n",
    "out_csv = os.path.join(path_dir_output, \"v5_transcription_postgen.csv\");\n",
    "df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"CSV écrit ->\", out_csv)\n",
    "\n",
    "out_payload = os.path.join(path_dir_output, \"v5_segments_payload.json\");\n",
    "try:\n",
    "    with open(out_payload, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "    print(\"Payload JSON écrit ->\", out_payload)\n",
    "except Exception as e:\n",
    "    print(\"Aucun payload à écrire ou erreur:\", e)"
   ],
   "id": "a23b85b3accd00cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV écrit -> /mnt/c/Users/Utilisateur/PycharmProjects/lumierelearning/notebook/4_-_Presentation_des_meches_KtwWjO/v5_transcription_postgen.csv\n",
      "Payload JSON écrit -> /mnt/c/Users/Utilisateur/PycharmProjects/lumierelearning/notebook/4_-_Presentation_des_meches_KtwWjO/v5_segments_payload.json\n"
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba1ee43",
   "metadata": {},
   "source": [
    "\n",
    "# Pipeline Pack Ultra‑Cohérente — Rask × LLM (**v4 — stricte, durée→mots, audit vitesse**)\n",
    "\n",
    "Objectif : générer **tous les segments en une seule requête** pour garantir un style homogène **et** un **respect strict du tempo** (durée → nombre de mots via `WPM`).  \n",
    "La qualité pédagogique prime, mais la longueur est **contrainte** segment par segment. Si le LLM dévie, une **normalisation stricte** recadre à l’exact nombre de mots.  \n",
    "En fin de pipeline, un **audit de vitesse parlée** vérifie le débit réel par segment.\n",
    "\n",
    "**Étapes :**\n",
    "1) Configuration (Rask, OpenAI, WPM)  \n",
    "2) Auth + fonctions Rask  \n",
    "3) Ingestion transcript + cibles (durée → mots)  \n",
    "4) Construction du pack (avec `exact_words`, `min_words`, `max_words` par segment)  \n",
    "5) Génération pack (une requête) → JSON **patchable Rask**  \n",
    "6) Régénération ciblée des segments hors bornes (2 passes max)  \n",
    "7) **Normalisation stricte**: chaque segment atteint **exactement** `exact_words` (LLM strict + fallback)  \n",
    "8) Audit fins/débuts + auto-fix (pas de phrase coupée)  \n",
    "9) Tableau AVANT / APRÈS (tailles)  \n",
    "10) **Audit vitesse** par segment (WPM) et statut OK/FAST/SLOW  \n",
    "11) Patch Rask (dry‑run par défaut)  \n",
    "12) Exports\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ffcfb150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:36:16.279428Z",
     "start_time": "2025-09-29T05:36:16.275851Z"
    }
   },
   "source": [
    "\n",
    "# (0) Dépendances (exécuter si nécessaire)\n",
    "# %pip install --quiet requests python-dotenv pandas tqdm openai\n"
   ],
   "outputs": [],
   "execution_count": 431
  },
  {
   "cell_type": "code",
   "id": "c7044b2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:36:16.347351Z",
     "start_time": "2025-09-29T05:36:16.321624Z"
    }
   },
   "source": [
    "\n",
    "# (1) Configuration & variables d'environnement\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Rask\n",
    "RASK_TOKEN = os.getenv(\"RASK_TOKEN\", \"\")\n",
    "RASK_CLIENT_ID = os.getenv(\"RASK_CLIENT_ID\", \"\")\n",
    "RASK_CLIENT_SECRET = os.getenv(\"RASK_CLIENT_SECRET\", \"\")\n",
    "\n",
    "# OpenAI\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-5-mini\")\n",
    "OPENAI_TEMPERATURE = float(os.getenv(\"OPENAI_TEMPERATURE\", \"0.2\"))\n",
    "OPENAI_MAX_RETRIES = int(os.getenv(\"OPENAI_MAX_RETRIES\", \"2\"))\n",
    "\n",
    "# Paramètres projet\n",
    "LANG_DEST = os.getenv(\"LANG_DEST\", \"fr-fr\")\n",
    "WPM = float(os.getenv(\"WPM\", \"147.0\"))                    # mots/minute cible\n",
    "LENGTH_TOLERANCE = int(os.getenv(\"LENGTH_TOLERANCE\", \"2\"))# ± mots autour de la cible pour la 1ère passe\n",
    "MIN_SENT_WORDS = int(os.getenv(\"MIN_SENT_WORDS\", \"7\"))    # fourchette indicative par phrase\n",
    "MAX_SENT_WORDS = int(os.getenv(\"MAX_SENT_WORDS\", \"22\"))\n",
    "RATE_TOL_PCT = float(os.getenv(\"RATE_TOL_PCT\", \"2.0\"))    # tolérance vitesse ±% autour du WPM\n",
    "STRICT_MAX_RETRIES = int(os.getenv(\"STRICT_MAX_RETRIES\", \"10\"))  # tentatives LLM pour exact N mots\n",
    "\n",
    "# Sélection du projet (nom ou URL app.rask.ai)\n",
    "PROJECT_SELECTOR = \"3_-_Presentation_des_moules_de_bougies_KtwWjO\"\n",
    "\n",
    "# Scope à traiter (None = tous)\n",
    "SEGMENTS_RANGE = None\n",
    "\n",
    "# Patch\n",
    "DRY_RUN = True         # True: prévisualiser; False: envoyer\n",
    "INCLUDE_TIMING = True # True pour pousser start/end\n",
    "\n",
    "print(\"Config OK —\", {\n",
    "    \"LANG_DEST\": LANG_DEST, \"WPM\": WPM, \"TOL_WORDS\": LENGTH_TOLERANCE,\n",
    "    \"SENT_RANGE\": f\"{MIN_SENT_WORDS}-{MAX_SENT_WORDS}\",\n",
    "    \"RATE_TOL_PCT\": RATE_TOL_PCT,\n",
    "    \"STRICT_MAX_RETRIES\": STRICT_MAX_RETRIES,\n",
    "    \"PROJECT_SELECTOR\": PROJECT_SELECTOR,\n",
    "    \"DRY_RUN\": DRY_RUN, \"INCLUDE_TIMING\": INCLUDE_TIMING\n",
    "})\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config OK — {'LANG_DEST': 'fr-fr', 'WPM': 147.0, 'TOL_WORDS': 2, 'SENT_RANGE': '7-22', 'RATE_TOL_PCT': 2.0, 'STRICT_MAX_RETRIES': 10, 'PROJECT_SELECTOR': '8_-_Pratique_2_utilisation_des_colorants_Hibou_KtwWjO', 'DRY_RUN': True, 'INCLUDE_TIMING': True}\n"
     ]
    }
   ],
   "execution_count": 432
  },
  {
   "cell_type": "code",
   "id": "8491428d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:36:17.132976Z",
     "start_time": "2025-09-29T05:36:16.399378Z"
    }
   },
   "source": [
    "\n",
    "# (2) Auth & helpers Rask\n",
    "import re, json, time, math\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import display\n",
    "\n",
    "TOKEN_URL = \"https://rask-prod.auth.us-east-2.amazoncognito.com/oauth2/token\"\n",
    "SCOPES = \"api/source api/input api/output api/limit\"\n",
    "\n",
    "PROJECTS_URL = \"https://api.rask.ai/v2/projects\"\n",
    "GET_PROJECT_URL = \"https://api.rask.ai/v2/projects/{project_id}\"\n",
    "TRANSCRIPTION_URL = \"https://api.rask.ai/v2/projects/{project_id}/transcription\"\n",
    "PATCH_SEGMENTS_URL = \"https://api.rask.ai/v2/projects/{project_id}/transcription/segments\"\n",
    "GENERATE_URL = \"https://api.rask.ai/v2/projects/{project_id}/generate\"\n",
    "\n",
    "def get_token(client_id: str, client_secret: str) -> str:\n",
    "    if not client_id or not client_secret:\n",
    "        raise RuntimeError(\"RASK_CLIENT_ID / RASK_CLIENT_SECRET manquants (ou fournir RASK_TOKEN).\")\n",
    "    r = requests.post(TOKEN_URL, data={\"grant_type\":\"client_credentials\",\"scope\":SCOPES},\n",
    "                      auth=(client_id, client_secret), timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"access_token\"]\n",
    "\n",
    "def build_headers() -> dict:\n",
    "    token = RASK_TOKEN or get_token(RASK_CLIENT_ID, RASK_CLIENT_SECRET)\n",
    "    return {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "HEADERS = build_headers()\n",
    "print(\"Auth Rask OK.\")\n",
    "\n",
    "def _normalize_name(s: str) -> str:\n",
    "    return re.sub(r\"[-\\s_]+\", \"\", (s or \"\").strip().lower())\n",
    "\n",
    "def project_id_from_app_url(url: str) -> str | None:\n",
    "    m = re.search(r\"/project/([0-9a-fA-F-]{36})\", str(url))\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def find_project_id_by_name(headers: dict, name: str, limit: int = 100) -> str | None:\n",
    "    target = _normalize_name(name); offset = 0\n",
    "    while True:\n",
    "        r = requests.get(PROJECTS_URL, headers=headers, params={\"offset\": offset, \"limit\": limit}, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        payload = r.json()\n",
    "        for p in payload.get(\"projects\", []):\n",
    "            if _normalize_name(p.get(\"name\")) == target:\n",
    "                return p[\"id\"]\n",
    "        offset += limit\n",
    "        if offset >= payload.get(\"total\", 0):\n",
    "            break\n",
    "    offset = 0\n",
    "    while True:\n",
    "        r = requests.get(PROJECTS_URL, headers=headers, params={\"offset\": offset, \"limit\": limit}, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        payload = r.json()\n",
    "        for p in payload.get(\"projects\", []):\n",
    "            if target in _normalize_name(p.get(\"name\")):\n",
    "                return p[\"id\"]\n",
    "        offset += limit\n",
    "        if offset >= payload.get(\"total\", 0):\n",
    "            break\n",
    "    return None\n",
    "\n",
    "def get_project(headers: dict, project_id: str) -> dict:\n",
    "    r = requests.get(GET_PROJECT_URL.format(project_id=project_id), headers=headers, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def guess_dst_lang(headers: dict, project_id: str, default=\"fr-fr\") -> str:\n",
    "    info = get_project(headers, project_id)\n",
    "    return (info.get(\"dst_lang\") or info.get(\"dstLanguage\") or default)\n",
    "\n",
    "def select_project_id(selector: str) -> str:\n",
    "    return project_id_from_app_url(selector) or find_project_id_by_name(HEADERS, selector) or            (_ for _ in ()).throw(RuntimeError(f\"Aucun projet trouvé pour: {selector}\"))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auth Rask OK.\n"
     ]
    }
   ],
   "execution_count": 433
  },
  {
   "cell_type": "code",
   "id": "56f33ff1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:36:19.568157Z",
     "start_time": "2025-09-29T05:36:17.147462Z"
    }
   },
   "source": [
    "\n",
    "# (3) Ingestion + cibles (durée → mots via WPM)\n",
    "def _parse_timecode(tc) -> float:\n",
    "    if isinstance(tc, (int, float)): return float(tc)\n",
    "    s = str(tc).strip().replace(\",\", \".\")\n",
    "    m = re.match(r\"^(?P<h>\\d{1,2}):(?P<m>\\d{2}):(?P<s>\\d{2})(?:\\.(?P<ms>\\d{1,3}))?$\", s)\n",
    "    if m:\n",
    "        h = int(m.group(\"h\")); mn = int(m.group(\"m\")); sec = int(m.group(\"s\")); ms = int(m.group(\"ms\") or 0)\n",
    "        return h*3600 + mn*60 + sec + ms/1000.0\n",
    "    return float(s)\n",
    "\n",
    "WORD_RE = re.compile(r\"\\b[\\w’'-]+\\b\", flags=re.UNICODE)\n",
    "def words_count(text: str) -> int:\n",
    "    return len(WORD_RE.findall(text or \"\"))\n",
    "\n",
    "def words_target_for_duration(duration_sec: float, wpm: float) -> int:\n",
    "    return max(0, int(round(wpm * (duration_sec / 60.0))))\n",
    "\n",
    "def spoken_rate_wpm(words: int, duration_sec: float) -> float:\n",
    "    return (words / max(0.5, float(duration_sec))) * 60.0\n",
    "\n",
    "def get_transcription_df(headers: dict, project_id: str, wpm: float) -> pd.DataFrame:\n",
    "    r = requests.get(TRANSCRIPTION_URL.format(project_id=project_id), headers=headers, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    rows = []\n",
    "    for seg in data.get(\"segments\", []):\n",
    "        start = seg.get(\"start\"); end = seg.get(\"end\")\n",
    "        dur = max(0.0, _parse_timecode(end) - _parse_timecode(start))\n",
    "        src = (seg.get(\"src\") or {}).get(\"text\", \"\")\n",
    "        dst = (seg.get(\"dst\") or {}).get(\"text\", \"\")\n",
    "        rows.append({\n",
    "            \"segment_id\": seg.get(\"id\"),\n",
    "            \"speaker\": seg.get(\"speaker\"),\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"duration_sec\": round(dur, 3),\n",
    "            \"src_text\": src,\n",
    "            \"dst_text\": dst,\n",
    "            \"dst_length\": words_count(dst),\n",
    "            \"estimation_length\": words_target_for_duration(dur, wpm),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "project_id = select_project_id(PROJECT_SELECTOR)\n",
    "dst_lang = guess_dst_lang(HEADERS, project_id, default=LANG_DEST)\n",
    "df = get_transcription_df(HEADERS, project_id, WPM)\n",
    "indices_to_process = list(range(len(df))) if SEGMENTS_RANGE is None else list(SEGMENTS_RANGE)\n",
    "\n",
    "print(\"Project ID:\", project_id, \"| dst_lang:\", dst_lang, \"| segments:\", len(df))\n",
    "display(df.head(8)[[\"segment_id\",\"start\",\"end\",\"duration_sec\",\"dst_length\",\"estimation_length\",\"dst_text\"]])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: 7602f534-dd28-4793-90ef-4e6bd848d04e | dst_lang: fr-fr | segments: 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                             segment_id         start           end  \\\n",
       "0  7062485a-d5ee-41a7-8f4b-92e1811fc354  00:00:00,619  00:00:06,290   \n",
       "1  59a9c338-d60f-4da6-b566-e524a1a64362  00:00:06,918  00:00:12,201   \n",
       "2  798b5160-d60b-4ce4-8cca-18612dce8e5a  00:00:12,640  00:00:22,521   \n",
       "3  ab857ca1-d57d-43aa-af3a-cbf10ec0211e  00:00:23,115  00:00:31,757   \n",
       "4  cf5e9d7c-b9e1-4e2e-a097-85aae1cf957e  00:00:32,792  00:00:45,797   \n",
       "5  e3ef803b-1c4d-4741-855f-ed50fe228067  00:00:46,561  00:01:00,602   \n",
       "6  8e39315a-8e31-4bba-86ed-6f00b396eac2  00:01:01,451  00:01:17,173   \n",
       "7  225cf057-3c7a-4bd6-9877-bb03046ab75a  00:01:17,988  00:01:32,114   \n",
       "\n",
       "   duration_sec  dst_length  estimation_length  \\\n",
       "0         5.671          21                 14   \n",
       "1         5.283          25                 13   \n",
       "2         9.881          24                 24   \n",
       "3         8.642          69                 21   \n",
       "4        13.005          23                 32   \n",
       "5        14.041          61                 34   \n",
       "6        15.722          50                 39   \n",
       "7        14.126          36                 35   \n",
       "\n",
       "                                            dst_text  \n",
       "0  Dans cette partie, nous découvrons les moules ...  \n",
       "1  Même en moulage, les mesures restent essentiel...  \n",
       "2  Comme pour les bougies en contenant, on pèse l...  \n",
       "3   Ici, nous obtenons 36 g d’eau. La cire étant ...  \n",
       "4   Ces 28,8 g constituent la masse totale de vot...  \n",
       "5  « Paraffine 40 % : 28,8 × 0,40 = 11,52 g, arro...  \n",
       "6  Soja 30 % : 28,8 × 0,30 = 8,64 g, arrondis à 9...  \n",
       "7  Acide stéarique 20 % : 28,8 × 0,20 = 5,76 g, a...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>dst_length</th>\n",
       "      <th>estimation_length</th>\n",
       "      <th>dst_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7062485a-d5ee-41a7-8f4b-92e1811fc354</td>\n",
       "      <td>00:00:00,619</td>\n",
       "      <td>00:00:06,290</td>\n",
       "      <td>5.671</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>Dans cette partie, nous découvrons les moules ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59a9c338-d60f-4da6-b566-e524a1a64362</td>\n",
       "      <td>00:00:06,918</td>\n",
       "      <td>00:00:12,201</td>\n",
       "      <td>5.283</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>Même en moulage, les mesures restent essentiel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>798b5160-d60b-4ce4-8cca-18612dce8e5a</td>\n",
       "      <td>00:00:12,640</td>\n",
       "      <td>00:00:22,521</td>\n",
       "      <td>9.881</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>Comme pour les bougies en contenant, on pèse l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ab857ca1-d57d-43aa-af3a-cbf10ec0211e</td>\n",
       "      <td>00:00:23,115</td>\n",
       "      <td>00:00:31,757</td>\n",
       "      <td>8.642</td>\n",
       "      <td>69</td>\n",
       "      <td>21</td>\n",
       "      <td>Ici, nous obtenons 36 g d’eau. La cire étant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cf5e9d7c-b9e1-4e2e-a097-85aae1cf957e</td>\n",
       "      <td>00:00:32,792</td>\n",
       "      <td>00:00:45,797</td>\n",
       "      <td>13.005</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>Ces 28,8 g constituent la masse totale de vot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e3ef803b-1c4d-4741-855f-ed50fe228067</td>\n",
       "      <td>00:00:46,561</td>\n",
       "      <td>00:01:00,602</td>\n",
       "      <td>14.041</td>\n",
       "      <td>61</td>\n",
       "      <td>34</td>\n",
       "      <td>« Paraffine 40 % : 28,8 × 0,40 = 11,52 g, arro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8e39315a-8e31-4bba-86ed-6f00b396eac2</td>\n",
       "      <td>00:01:01,451</td>\n",
       "      <td>00:01:17,173</td>\n",
       "      <td>15.722</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>Soja 30 % : 28,8 × 0,30 = 8,64 g, arrondis à 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>225cf057-3c7a-4bd6-9877-bb03046ab75a</td>\n",
       "      <td>00:01:17,988</td>\n",
       "      <td>00:01:32,114</td>\n",
       "      <td>14.126</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>Acide stéarique 20 % : 28,8 × 0,20 = 5,76 g, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 434
  },
  {
   "cell_type": "code",
   "id": "f23c2d0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:36:19.974241Z",
     "start_time": "2025-09-29T05:36:19.924441Z"
    }
   },
   "source": [
    "\n",
    "# (4) Pack global — contraintes de longueur exactes\n",
    "LEXICON = [\n",
    "    \"balance\", \"fondoir\", \"bain-marie\", \"cuillère en bois\", \"parfums\",\n",
    "    \"colorants\", \"mèches\", \"moules\", \"pastille métallique\", \"support de mèche\",\n",
    "    \"pipettes\", \"cire naturelle\"\n",
    "]\n",
    "\n",
    "def build_segments_pack(df: pd.DataFrame, indices: list[int], tol: int = LENGTH_TOLERANCE) -> dict:\n",
    "    dfx = df.reset_index(drop=True)\n",
    "    pack = []\n",
    "    for i in indices:\n",
    "        base = str(dfx.at[i, \"dst_text\"] or dfx.at[i, \"src_text\"] or \"\").strip()\n",
    "        prev_text = str(dfx.at[i-1, \"dst_text\"]).strip() if i-1 >= 0 else \"\"\n",
    "        next_text = str(dfx.at[i+1, \"dst_text\"]).strip() if i+1 < len(dfx) else \"\"\n",
    "        tgt = int(dfx.at[i, \"estimation_length\"])\n",
    "        mn = max(1, tgt - tol)\n",
    "        mx = tgt + tol\n",
    "        pack.append({\n",
    "            \"index\": i,\n",
    "            \"id\": str(dfx.at[i, \"segment_id\"]),\n",
    "            \"exact_words\": tgt,\n",
    "            \"min_words\": mn,\n",
    "            \"max_words\": mx,\n",
    "            \"duration_sec\": float(dfx.at[i, \"duration_sec\"]),\n",
    "            \"base_text\": base,\n",
    "            \"prev_text\": prev_text,\n",
    "            \"next_text\": next_text\n",
    "        })\n",
    "    context = {\n",
    "        \"language\": LANG_DEST,\n",
    "        \"lexicon_preferred\": LEXICON,\n",
    "        \"style\": \"présentation de matériel, pédagogique, clair, précis, ton professionnel sobre\",\n",
    "        \"audience\": \"débutant à intermédiaire\"\n",
    "    }\n",
    "    return {\"context\": context, \"segments\": pack}\n",
    "\n",
    "segments_pack = build_segments_pack(df, indices_to_process, tol=LENGTH_TOLERANCE)\n",
    "print(\"Pack prêt:\", len(segments_pack[\"segments\"]), \"segments\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pack prêt: 22 segments\n"
     ]
    }
   ],
   "execution_count": 435
  },
  {
   "cell_type": "code",
   "id": "28c9804f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:36:20.251245Z",
     "start_time": "2025-09-29T05:36:20.145438Z"
    }
   },
   "source": [
    "\n",
    "# (5) Client OpenAI + prompts pack / strict / parse JSON\n",
    "_openai_mode = None\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    _client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    _openai_mode = \"new\"\n",
    "except Exception:\n",
    "    try:\n",
    "        import openai\n",
    "        openai.api_key = OPENAI_API_KEY\n",
    "        _openai_mode = \"legacy\"\n",
    "    except Exception:\n",
    "        _openai_mode = None\n",
    "\n",
    "if not OPENAI_API_KEY or not _openai_mode:\n",
    "    print(\"AVERTISSEMENT: OpenAI indisponible. Fallback sur textes existants.\")\n",
    "\n",
    "GLOBAL_CHARTER = (\n",
    "    \"Génère tous les segments en une seule passe pour un style homogène. \"\n",
    "    \"Chaque segment est un paragraphe complet, autoportant, ponctué, ne se poursuit jamais dans le suivant. \"\n",
    "    \"Style pédagogique et précis, sans pas-à-pas; lexique constant: \" + \", \".join(LEXICON) + \".\"\n",
    ")\n",
    "\n",
    "def build_pack_prompt(lang_dest: str, pack: dict, smin: int, smax: int) -> list[dict]:\n",
    "    system = (\n",
    "        f\"Tu es un rédacteur pédagogique expert. Tu écris en {lang_dest}. \"\n",
    "        f\"{GLOBAL_CHARTER} Respecte des phrases simples courtes à moyennes. \"\n",
    "        \"RENVOIE UNIQUEMENT un JSON **valide** directement patchable par l'API Rask.\"\n",
    "    )\n",
    "    user_payload = {\n",
    "        \"contraintes_globales\": {\n",
    "            \"phrases\": f\"{smin}-{smax} mots/phrase environ\",\n",
    "            \"pas_d_actions\": True,\n",
    "            \"pas_de_listes\": True,\n",
    "            \"segment_independant\": True,\n",
    "            \"transition_douce\": True,\n",
    "            \"interdit_finir_par\": [\"et\",\"mais\",\"ou\",\"donc\",\"or\",\"ni\",\"car\",\"cela\",\"les\"]\n",
    "        },\n",
    "        \"règle_longueur\": \"Pour chaque segment, produire **exactement** <exact_words> mots (±2 seulement si la fluidité l'exige).\",\n",
    "        \"segments\": [\n",
    "            {\n",
    "                \"id\": it[\"id\"],\n",
    "                \"exact_words\": it[\"exact_words\"],\n",
    "                \"min_words\": it[\"min_words\"],\n",
    "                \"max_words\": it[\"max_words\"],\n",
    "                \"duration_sec\": it[\"duration_sec\"],\n",
    "                \"base_text\": it[\"base_text\"],\n",
    "                \"prev_text\": it[\"prev_text\"],\n",
    "                \"next_text\": it[\"next_text\"]\n",
    "            } for it in pack[\"segments\"]\n",
    "        ],\n",
    "        \"sortie_json_patch_rask\": f'[{{\"id\":\"<segment_id>\",\"dst\":{{\"text\":\"<texte EXACT <exact_words> mots>\",\"lang\":\"{LANG_DEST}\"}}}}]'\n",
    "    }\n",
    "    return [{\"role\":\"system\",\"content\":system},\n",
    "            {\"role\":\"user\",\"content\":json.dumps(user_payload, ensure_ascii=False)}]\n",
    "\n",
    "def build_strict_segment_prompt(lang_dest: str, base_text: str, prev_text: str, next_text: str,\n",
    "                                exact_words: int, smin: int, smax: int) -> list[dict]:\n",
    "    system = (\n",
    "        f\"Tu écris en {lang_dest} un segment unique, très fluide, pédagogique. Sans mots clés scientisiques compliqué\"\n",
    "        \"Un seul paragraphe, ponctuation finale, sans listes ni actions procédurales. \"\n",
    "        f\"Le texte DOIT contenir **exactement {exact_words} mots** (compte standard). Sans anglissime\"\n",
    "    )\n",
    "    user = {\n",
    "        \"exact_words\": exact_words,\n",
    "        \"phrases\": f\"{smin}-{smax} mots/phrase environ\",\n",
    "        \"contexte\": {\"prev_text\": prev_text, \"next_text\": next_text},\n",
    "        \"base_text\": base_text,\n",
    "        \"sortie\": {\"format\": \"texte seul, sans guillemets, sans balises\"}\n",
    "    }\n",
    "    return [{\"role\":\"system\",\"content\":system},\n",
    "            {\"role\":\"user\",\"content\":json.dumps(user, ensure_ascii=False)}]\n",
    "\n",
    "def openai_chat(messages: list[dict], model: str, temperature: float) -> str:\n",
    "    last_err = None\n",
    "    for _ in range(1 + OPENAI_MAX_RETRIES):\n",
    "        try:\n",
    "            if _openai_mode == \"new\":\n",
    "                resp = _client.chat.completions.create(model=model,\n",
    "                                                       # temperature=temperature,\n",
    "                                                       messages=messages)\n",
    "                return resp.choices[0].message.content.strip()\n",
    "            else:\n",
    "                resp = openai.ChatCompletion.create(model=model,\n",
    "                                                    # temperature=temperature,\n",
    "                                                    messages=messages)\n",
    "                return resp[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(0.8)\n",
    "    raise RuntimeError(f\"Echec OpenAI après retries: {last_err}\")\n",
    "\n",
    "def parse_patch_json(raw: str) -> list[dict]:\n",
    "    try:\n",
    "        data = json.loads(raw)\n",
    "        if isinstance(data, dict) and \"segments\" in data:\n",
    "            return data[\"segments\"]\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "    except json.JSONDecodeError:\n",
    "        m = re.search(r\"```json\\s*(\\[.*?\\])\\s*```\", raw, flags=re.DOTALL)\n",
    "        if m: return json.loads(m.group(1))\n",
    "        m2 = re.search(r\"(\\[\\s*\\{.*\\}\\s*\\])\", raw, flags=re.DOTALL)\n",
    "        if m2: return json.loads(m2.group(1))\n",
    "    raise RuntimeError(\"Réponse LLM non JSON patchable Rask.\")\n"
   ],
   "outputs": [],
   "execution_count": 436
  },
  {
   "cell_type": "code",
   "id": "79bc8b3f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-29T05:36:20.274798Z"
    }
   },
   "source": [
    "\n",
    "# (6) Génération pack + régénération bornes + normalisation stricte EXACT\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def generate_pack(df: pd.DataFrame,\n",
    "                  lang_dest: str,\n",
    "                  indices: list[int],\n",
    "                  tol_words: int,\n",
    "                  smin: int, smax: int,\n",
    "                  model: str = OPENAI_MODEL,\n",
    "                  temperature: float = OPENAI_TEMPERATURE) -> pd.DataFrame:\n",
    "    dfx = df.reset_index(drop=True).copy()\n",
    "    pack = build_segments_pack(dfx, indices, tol=tol_words)\n",
    "\n",
    "    # Pass 1 — pack\n",
    "    if not OPENAI_API_KEY or _openai_mode is None:\n",
    "        print(\"OpenAI indisponible: fallback base_text.\")\n",
    "        results = [{\"id\": it[\"id\"], \"dst\": {\"text\": it[\"base_text\"], \"lang\": lang_dest}} for it in pack[\"segments\"]]\n",
    "    else:\n",
    "        msgs = build_pack_prompt(lang_dest, pack, smin=smin, smax=smax)\n",
    "        raw = openai_chat(msgs, model=model, temperature=temperature)\n",
    "        results = parse_patch_json(raw)\n",
    "\n",
    "    # Injection\n",
    "    if \"new_text\" not in dfx.columns: dfx[\"new_text\"] = pd.NA\n",
    "    if \"new_length\" not in dfx.columns: dfx[\"new_length\"] = pd.NA\n",
    "    sid_to_idx = {str(dfx.at[i,\"segment_id\"]): i for i in range(len(dfx))}\n",
    "    for item in results:\n",
    "        sid = item.get(\"id\") or item.get(\"segment_id\")\n",
    "        txt = (item.get(\"dst\",{}).get(\"text\") or item.get(\"text\") or \"\").strip()\n",
    "        if sid in sid_to_idx:\n",
    "            j = sid_to_idx[sid]\n",
    "            dfx.at[j,\"new_text\"] = txt\n",
    "            dfx.at[j,\"new_length\"] = words_count(txt)\n",
    "\n",
    "    # Régénération ciblée: segments hors [min,max] (2 passes max)\n",
    "    def validate_lengths(dfa: pd.DataFrame, idxs: list[int]) -> pd.DataFrame:\n",
    "        rows = []\n",
    "        for i in idxs:\n",
    "            tgt = int(dfa.at[i,\"estimation_length\"])\n",
    "            mn, mx = max(1, tgt - tol_words), tgt + tol_words\n",
    "            nl = int(dfa.at[i,\"new_length\"] or 0)\n",
    "            if not (mn <= nl <= mx):\n",
    "                rows.append({\"index\": i, \"segment_id\": dfa.at[i,\"segment_id\"],\n",
    "                             \"target\": tgt, \"min\": mn, \"max\": mx, \"have\": nl})\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    def build_single_prompt(base_text: str, prev_text: str, next_text: str,\n",
    "                            exact_words: int) -> list[dict]:\n",
    "        return build_strict_segment_prompt(lang_dest, base_text, prev_text, next_text, exact_words, smin, smax)\n",
    "\n",
    "    for p in range(2):\n",
    "        bad = validate_lengths(dfx, indices)\n",
    "        if bad.empty or not (OPENAI_API_KEY and _openai_mode):\n",
    "            break\n",
    "        print(f\"Régénération ciblée (bornes) — pass {p+1}: {len(bad)} segments\")\n",
    "        for _, row in bad.iterrows():\n",
    "            i = int(row[\"index\"])\n",
    "            target = int(row[\"target\"])\n",
    "            base = str(dfx.at[i,\"new_text\"] or dfx.at[i,\"dst_text\"] or dfx.at[i,\"src_text\"] or \"\").strip()\n",
    "            prev_text = str(dfx.at[i-1,\"new_text\"] or dfx.at[i-1,\"dst_text\"] or \"\").strip() if i-1 >= 0 else \"\"\n",
    "            next_text = str(dfx.at[i+1,\"new_text\"] or dfx.at[i+1,\"dst_text\"] or \"\").strip() if i+1 < len(dfx) else \"\"\n",
    "            msgs = build_single_prompt(base, prev_text, next_text, target)\n",
    "            cand = openai_chat(msgs, model=model, temperature=temperature).strip()\n",
    "            dfx.at[i,\"new_text\"] = cand\n",
    "            dfx.at[i,\"new_length\"] = words_count(cand)\n",
    "\n",
    "    # Normalisation stricte EXACT = target (LLM strict + fallback)\n",
    "    def exact_length_normalize(dfa: pd.DataFrame, idxs: list[int]) -> pd.DataFrame:\n",
    "        out = dfa.copy()\n",
    "        for i in idxs:\n",
    "            target = int(out.at[i,\"estimation_length\"])\n",
    "            cur = int(out.at[i,\"new_length\"] or 0)\n",
    "            if cur == target:\n",
    "                continue\n",
    "            base = str(out.at[i,\"new_text\"] or out.at[i,\"dst_text\"] or out.at[i,\"src_text\"] or \"\").strip()\n",
    "            prev_text = str(out.at[i-1,\"new_text\"] or out.at[i-1,\"dst_text\"] or \"\").strip() if i-1 >= 0 else \"\"\n",
    "            next_text = str(out.at[i+1,\"new_text\"] or out.at[i+1,\"dst_text\"] or \"\").strip() if i+1 < len(out) else \"\"\n",
    "\n",
    "            # Tentatives LLM exact N mots\n",
    "            ok = False\n",
    "            if OPENAI_API_KEY and _openai_mode:\n",
    "                for _ in range(STRICT_MAX_RETRIES):\n",
    "                    msgs = build_strict_segment_prompt(LANG_DEST, base, prev_text, next_text, target, smin, smax)\n",
    "                    candidate = openai_chat(msgs, model=model, temperature=temperature).strip()\n",
    "                    if words_count(candidate) == target:\n",
    "                        out.at[i,\"new_text\"] = candidate\n",
    "                        out.at[i,\"new_length\"] = target\n",
    "                        ok = True\n",
    "                        break\n",
    "            if ok:\n",
    "                continue\n",
    "\n",
    "            # Fallback: compression/expansion soft\n",
    "            txt = base\n",
    "            cur = words_count(txt)\n",
    "            if cur > target:\n",
    "                sentences = re.split(r\"(?<=[.!?…])\\s+\", txt.strip())\n",
    "                # retirer la phrase la plus longue tant qu'on dépasse\n",
    "                while words_count(\" \".join(sentences)) > target and len(sentences) > 1:\n",
    "                    idx_long = max(range(len(sentences)), key=lambda k: words_count(sentences[k]))\n",
    "                    del sentences[idx_long]\n",
    "                txt = \" \".join(sentences).strip()\n",
    "                toks = WORD_RE.findall(txt)\n",
    "                if len(toks) > target:\n",
    "                    toks = toks[:target]\n",
    "                txt = \" \".join(toks)\n",
    "            elif cur < target:\n",
    "                pad1 = \" Cet aperçu fixe des repères clairs.\"\n",
    "                pad2 = \" Vous disposerez ainsi d’une base fiable.\"\n",
    "                while words_count(txt) < target and txt.count(pad1) < 2:\n",
    "                    txt = (txt + pad1).strip()\n",
    "                if words_count(txt) < target:\n",
    "                    txt = (txt + pad2).strip()\n",
    "                toks = WORD_RE.findall(txt)\n",
    "                if len(toks) > target:\n",
    "                    toks = toks[:target]\n",
    "                txt = \" \".join(toks)\n",
    "\n",
    "            out.at[i,\"new_text\"] = txt.strip()\n",
    "            out.at[i,\"new_length\"] = words_count(txt)\n",
    "        return out\n",
    "\n",
    "    dfx = exact_length_normalize(dfx, indices)\n",
    "    return dfx\n",
    "\n",
    "df = generate_pack(df, LANG_DEST, indices_to_process, tol_words=LENGTH_TOLERANCE,\n",
    "                   smin=MIN_SENT_WORDS, smax=MAX_SENT_WORDS)\n",
    "print(\"Génération + normalisation strictes terminées.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3726b6ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:36:07.248950800Z",
     "start_time": "2025-09-28T22:18:24.190028Z"
    }
   },
   "source": [
    "\n",
    "# (7) Audit frontières + auto-fix (fins propres, débuts nets)\n",
    "TERM_PUNCT_RE = re.compile(r\"[.!?…]$\")\n",
    "WEAK_START_RE = re.compile(r\"^(?:et|mais|ou|donc|or|ni|car|cela|les)\\b\", re.IGNORECASE)\n",
    "ORPHAN_END_RE = re.compile(r\"\\b(?:et|mais|ou|donc|or|ni|car|cela|les)\\s*$\", re.IGNORECASE)\n",
    "\n",
    "def sentence_tokens(text: str) -> list[str]:\n",
    "    s = (text or \"\").strip()\n",
    "    if not s: return []\n",
    "    parts = re.split(r\"(?<=[.!?…])\\s+\", s)\n",
    "    return [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "def audit_boundaries(df: pd.DataFrame, indices: list[int],\n",
    "                     smin: int, smax: int) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for i in indices:\n",
    "        txt = (df.at[i,\"new_text\"] or \"\").strip()\n",
    "        sins = sentence_tokens(txt)\n",
    "        issues = []\n",
    "        if not TERM_PUNCT_RE.search(txt): issues.append(\"no_terminal_punct\")\n",
    "        if ORPHAN_END_RE.search(txt): issues.append(\"orphan_connector_end\")\n",
    "        if i+1 < len(df):\n",
    "            nxt = (df.at[i+1,\"new_text\"] or \"\").strip()\n",
    "            if WEAK_START_RE.search(nxt): issues.append(\"weak_start_next\")\n",
    "        if len(sins) == 0: issues.append(\"empty_segment\")\n",
    "        if len(sins) > 4: issues.append(\"too_many_sentences\")\n",
    "        for s in sins:\n",
    "            wc = len(WORD_RE.findall(s))\n",
    "            if wc < smin: issues.append(\"sentence_too_short\")\n",
    "            if wc > smax: issues.append(\"sentence_too_long\")\n",
    "        if issues:\n",
    "            rows.append({\"index\": i, \"segment_id\": df.at[i,\"segment_id\"], \"issues\": \", \".join(sorted(set(issues)))})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def polish_end(text: str) -> str:\n",
    "    s = (text or \"\").strip()\n",
    "    s = ORPHAN_END_RE.sub(\"\", s).strip()\n",
    "    if not TERM_PUNCT_RE.search(s):\n",
    "        s += \".\"\n",
    "    return re.sub(r\"\\s{2,}\", \" \", s)\n",
    "\n",
    "def polish_start(text: str) -> str:\n",
    "    s = (text or \"\").strip()\n",
    "    if WEAK_START_RE.match(s):\n",
    "        s = WEAK_START_RE.sub(\"Ensuite,\", s, count=1)\n",
    "        s = re.sub(r\"\\s{2,}\", \" \", s).strip()\n",
    "        if s: s = s[0].upper() + s[1:]\n",
    "    return s\n",
    "\n",
    "def auto_fix_boundaries(df: pd.DataFrame, indices: list[int]) -> pd.DataFrame:\n",
    "    dfx = df.copy()\n",
    "    for i in indices:\n",
    "        s = (dfx.at[i,\"new_text\"] or \"\").strip()\n",
    "        s = polish_end(s)\n",
    "        dfx.at[i,\"new_text\"] = s\n",
    "        dfx.at[i,\"new_length\"] = words_count(s)\n",
    "        if i+1 < len(dfx):\n",
    "            nxt = (dfx.at[i+1,\"new_text\"] or \"\").strip()\n",
    "            nxt = polish_start(nxt)\n",
    "            dfx.at[i+1,\"new_text\"] = nxt\n",
    "            dfx.at[i+1,\"new_length\"] = words_count(nxt)\n",
    "    return dfx\n",
    "\n",
    "issues_df = audit_boundaries(df, indices_to_process, smin=MIN_SENT_WORDS, smax=MAX_SENT_WORDS)\n",
    "print(\"Issues frontières détectées:\", len(issues_df))\n",
    "display(issues_df.head(20))\n",
    "\n",
    "df = auto_fix_boundaries(df, indices_to_process)\n",
    "\n",
    "issues_after = audit_boundaries(df, indices_to_process, smin=MIN_SENT_WORDS, smax=MAX_SENT_WORDS)\n",
    "print(\"Issues restantes après fix:\", len(issues_after))\n",
    "display(issues_after.head(20))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues frontières détectées: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   index                            segment_id              issues\n",
       "0      4  f1bdfd4a-7283-49b6-95ba-b7de7bf4b49c   sentence_too_long\n",
       "1      5  40fe5576-2765-4e75-b2d4-e9e779ec338d   sentence_too_long\n",
       "2      6  2caf09cf-05c5-44a8-87d7-c53cbc52abff  too_many_sentences"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>f1bdfd4a-7283-49b6-95ba-b7de7bf4b49c</td>\n",
       "      <td>sentence_too_long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>40fe5576-2765-4e75-b2d4-e9e779ec338d</td>\n",
       "      <td>sentence_too_long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2caf09cf-05c5-44a8-87d7-c53cbc52abff</td>\n",
       "      <td>too_many_sentences</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues restantes après fix: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   index                            segment_id              issues\n",
       "0      4  f1bdfd4a-7283-49b6-95ba-b7de7bf4b49c   sentence_too_long\n",
       "1      5  40fe5576-2765-4e75-b2d4-e9e779ec338d   sentence_too_long\n",
       "2      6  2caf09cf-05c5-44a8-87d7-c53cbc52abff  too_many_sentences"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>f1bdfd4a-7283-49b6-95ba-b7de7bf4b49c</td>\n",
       "      <td>sentence_too_long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>40fe5576-2765-4e75-b2d4-e9e779ec338d</td>\n",
       "      <td>sentence_too_long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2caf09cf-05c5-44a8-87d7-c53cbc52abff</td>\n",
       "      <td>too_many_sentences</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 425
  },
  {
   "cell_type": "code",
   "id": "7dd94e14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:36:07.250958900Z",
     "start_time": "2025-09-28T22:18:24.244223Z"
    }
   },
   "source": [
    "\n",
    "# (8) Visualisation AVANT / APRÈS + tailles\n",
    "view_cols = [\"segment_id\",\"start\",\"end\",\"duration_sec\",\"estimation_length\",\"dst_text\",\"dst_length\",\"new_text\",\"new_length\"]\n",
    "table = df.loc[indices_to_process, view_cols].copy()\n",
    "display(table.head(20))\n",
    "\n",
    "table.to_csv(\"v4_pack_avant_apres.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Export -> v4_pack_avant_apres.csv\")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             segment_id         start           end  \\\n",
       "0  8d7a71c7-84e7-4be4-addf-8d69c3d7c0b3  00:00:00,738  00:00:10,418   \n",
       "1  fc98262d-4ef3-429a-9d85-3057c5d999c9  00:00:10,418  00:00:13,913   \n",
       "2  aa4deb66-623c-4c45-9ba3-d99bbe9418bd  00:00:14,354  00:00:30,025   \n",
       "3  342b2806-3672-4035-8971-548b78a169f0  00:00:30,823  00:00:35,186   \n",
       "4  f1bdfd4a-7283-49b6-95ba-b7de7bf4b49c  00:00:35,645  00:00:54,694   \n",
       "5  40fe5576-2765-4e75-b2d4-e9e779ec338d  00:00:55,526  00:01:13,981   \n",
       "6  2caf09cf-05c5-44a8-87d7-c53cbc52abff  00:01:15,560  00:02:01,074   \n",
       "7  5063a8c7-38bf-488b-b18f-eb94001b248c  00:02:01,400  00:02:11,290   \n",
       "8  54091848-748e-4a99-aea0-1e2eb40988d3  00:02:11,290  00:02:21,110   \n",
       "9  adf33389-a2c8-417b-860d-760bb039ff30  00:02:21,689  00:02:28,724   \n",
       "\n",
       "   duration_sec  estimation_length  \\\n",
       "0         9.680                 24   \n",
       "1         3.495                  9   \n",
       "2        15.671                 38   \n",
       "3         4.363                 11   \n",
       "4        19.049                 47   \n",
       "5        18.455                 45   \n",
       "6        45.514                112   \n",
       "7         9.890                 24   \n",
       "8         9.820                 24   \n",
       "9         7.035                 17   \n",
       "\n",
       "                                            dst_text  dst_length  \\\n",
       "0  Les cires jouent un rôle essentiel dans la fab...          24   \n",
       "1  Le choix de la cire influence directement la q...           9   \n",
       "2  La cire d’abeille, prisée pour sa qualité exce...          38   \n",
       "3  Considérée comme 100 pourcent  naturelle elle ...          11   \n",
       "4  La cire de soja, en plus de brûler lentement, ...          47   \n",
       "5  La cire de soja, provenant de ressources renou...          45   \n",
       "6  La cire de paraffine bien que très répandue da...         112   \n",
       "7  Outre ses propriétés esthétiques l’acide stéar...          24   \n",
       "8  L’acide stéarique est également un agent blanc...          24   \n",
       "9  Son intérêt ne s’arrête pas là, car il renforc...          17   \n",
       "\n",
       "                                            new_text new_length  \n",
       "0  Les cires déterminent la combustion, l'aspect ...         24  \n",
       "1  Le choix de la cire naturelle influence la qua...          9  \n",
       "2  La cire d'abeille est une cire naturelle offra...         38  \n",
       "3  Considérée comme cire naturelle à 100%, elle e...         11  \n",
       "4  La cire de soja, cire naturelle issue de resso...         47  \n",
       "5  La cire de paraffine, issue de la pétrochimie,...         45  \n",
       "6  La paraffine, très répandue, offre une mise en...        112  \n",
       "7  L'acide stéarique améliore la texture, l'opaci...         24  \n",
       "8  L'acide stéarique agit aussi comme agent blanc...         24  \n",
       "9  Son intérêt dépasse l'esthétique car il renfor...         17  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>estimation_length</th>\n",
       "      <th>dst_text</th>\n",
       "      <th>dst_length</th>\n",
       "      <th>new_text</th>\n",
       "      <th>new_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8d7a71c7-84e7-4be4-addf-8d69c3d7c0b3</td>\n",
       "      <td>00:00:00,738</td>\n",
       "      <td>00:00:10,418</td>\n",
       "      <td>9.680</td>\n",
       "      <td>24</td>\n",
       "      <td>Les cires jouent un rôle essentiel dans la fab...</td>\n",
       "      <td>24</td>\n",
       "      <td>Les cires déterminent la combustion, l'aspect ...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fc98262d-4ef3-429a-9d85-3057c5d999c9</td>\n",
       "      <td>00:00:10,418</td>\n",
       "      <td>00:00:13,913</td>\n",
       "      <td>3.495</td>\n",
       "      <td>9</td>\n",
       "      <td>Le choix de la cire influence directement la q...</td>\n",
       "      <td>9</td>\n",
       "      <td>Le choix de la cire naturelle influence la qua...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa4deb66-623c-4c45-9ba3-d99bbe9418bd</td>\n",
       "      <td>00:00:14,354</td>\n",
       "      <td>00:00:30,025</td>\n",
       "      <td>15.671</td>\n",
       "      <td>38</td>\n",
       "      <td>La cire d’abeille, prisée pour sa qualité exce...</td>\n",
       "      <td>38</td>\n",
       "      <td>La cire d'abeille est une cire naturelle offra...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>342b2806-3672-4035-8971-548b78a169f0</td>\n",
       "      <td>00:00:30,823</td>\n",
       "      <td>00:00:35,186</td>\n",
       "      <td>4.363</td>\n",
       "      <td>11</td>\n",
       "      <td>Considérée comme 100 pourcent  naturelle elle ...</td>\n",
       "      <td>11</td>\n",
       "      <td>Considérée comme cire naturelle à 100%, elle e...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1bdfd4a-7283-49b6-95ba-b7de7bf4b49c</td>\n",
       "      <td>00:00:35,645</td>\n",
       "      <td>00:00:54,694</td>\n",
       "      <td>19.049</td>\n",
       "      <td>47</td>\n",
       "      <td>La cire de soja, en plus de brûler lentement, ...</td>\n",
       "      <td>47</td>\n",
       "      <td>La cire de soja, cire naturelle issue de resso...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40fe5576-2765-4e75-b2d4-e9e779ec338d</td>\n",
       "      <td>00:00:55,526</td>\n",
       "      <td>00:01:13,981</td>\n",
       "      <td>18.455</td>\n",
       "      <td>45</td>\n",
       "      <td>La cire de soja, provenant de ressources renou...</td>\n",
       "      <td>45</td>\n",
       "      <td>La cire de paraffine, issue de la pétrochimie,...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2caf09cf-05c5-44a8-87d7-c53cbc52abff</td>\n",
       "      <td>00:01:15,560</td>\n",
       "      <td>00:02:01,074</td>\n",
       "      <td>45.514</td>\n",
       "      <td>112</td>\n",
       "      <td>La cire de paraffine bien que très répandue da...</td>\n",
       "      <td>112</td>\n",
       "      <td>La paraffine, très répandue, offre une mise en...</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5063a8c7-38bf-488b-b18f-eb94001b248c</td>\n",
       "      <td>00:02:01,400</td>\n",
       "      <td>00:02:11,290</td>\n",
       "      <td>9.890</td>\n",
       "      <td>24</td>\n",
       "      <td>Outre ses propriétés esthétiques l’acide stéar...</td>\n",
       "      <td>24</td>\n",
       "      <td>L'acide stéarique améliore la texture, l'opaci...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54091848-748e-4a99-aea0-1e2eb40988d3</td>\n",
       "      <td>00:02:11,290</td>\n",
       "      <td>00:02:21,110</td>\n",
       "      <td>9.820</td>\n",
       "      <td>24</td>\n",
       "      <td>L’acide stéarique est également un agent blanc...</td>\n",
       "      <td>24</td>\n",
       "      <td>L'acide stéarique agit aussi comme agent blanc...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adf33389-a2c8-417b-860d-760bb039ff30</td>\n",
       "      <td>00:02:21,689</td>\n",
       "      <td>00:02:28,724</td>\n",
       "      <td>7.035</td>\n",
       "      <td>17</td>\n",
       "      <td>Son intérêt ne s’arrête pas là, car il renforc...</td>\n",
       "      <td>17</td>\n",
       "      <td>Son intérêt dépasse l'esthétique car il renfor...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export -> v4_pack_avant_apres.csv\n"
     ]
    }
   ],
   "execution_count": 426
  },
  {
   "cell_type": "code",
   "id": "267e7335",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:36:07.252966500Z",
     "start_time": "2025-09-28T22:18:24.445766Z"
    }
   },
   "source": [
    "\n",
    "# (9) Audit vitesse parlée (WPM) par segment + statut\n",
    "def rate_status(rate_wpm: float, target_wpm: float, tol_pct: float) -> str:\n",
    "    if target_wpm <= 0: return \"NA\"\n",
    "    delta_pct = 100.0 * (rate_wpm - target_wpm) / target_wpm\n",
    "    if abs(delta_pct) <= tol_pct:\n",
    "        return \"OK\"\n",
    "    return \"FAST\" if delta_pct > 0 else \"SLOW\"\n",
    "\n",
    "rate_rows = []\n",
    "for i in indices_to_process:\n",
    "    d = float(df.at[i,\"duration_sec\"] or 0.0)\n",
    "    w = int(df.at[i,\"new_length\"] or 0)\n",
    "    tgt = int(df.at[i,\"estimation_length\"] or 0)\n",
    "    rate = spoken_rate_wpm(w, d) if d > 0 else 0.0\n",
    "    status = rate_status(rate, WPM, RATE_TOL_PCT)\n",
    "    rate_rows.append({\n",
    "        \"segment_id\": df.at[i,\"segment_id\"],\n",
    "        \"duration_sec\": d,\n",
    "        \"target_words\": tgt,\n",
    "        \"new_length\": w,\n",
    "        \"rate_wpm\": round(rate, 1),\n",
    "        \"target_wpm\": WPM,\n",
    "        \"rate_deviation_pct\": round(100.0*(rate-WPM)/WPM, 1) if WPM > 0 else 0.0,\n",
    "        \"rate_status\": status\n",
    "    })\n",
    "\n",
    "rate_df = pd.DataFrame(rate_rows)\n",
    "display(rate_df.head(20))\n",
    "\n",
    "rate_df.to_csv(\"v4_audit_vitesse.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Export -> v4_audit_vitesse.csv\")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             segment_id  duration_sec  target_words  \\\n",
       "0  8d7a71c7-84e7-4be4-addf-8d69c3d7c0b3         9.680            24   \n",
       "1  fc98262d-4ef3-429a-9d85-3057c5d999c9         3.495             9   \n",
       "2  aa4deb66-623c-4c45-9ba3-d99bbe9418bd        15.671            38   \n",
       "3  342b2806-3672-4035-8971-548b78a169f0         4.363            11   \n",
       "4  f1bdfd4a-7283-49b6-95ba-b7de7bf4b49c        19.049            47   \n",
       "5  40fe5576-2765-4e75-b2d4-e9e779ec338d        18.455            45   \n",
       "6  2caf09cf-05c5-44a8-87d7-c53cbc52abff        45.514           112   \n",
       "7  5063a8c7-38bf-488b-b18f-eb94001b248c         9.890            24   \n",
       "8  54091848-748e-4a99-aea0-1e2eb40988d3         9.820            24   \n",
       "9  adf33389-a2c8-417b-860d-760bb039ff30         7.035            17   \n",
       "\n",
       "   new_length  rate_wpm  target_wpm  rate_deviation_pct rate_status  \n",
       "0          24     148.8       147.0                 1.2          OK  \n",
       "1           9     154.5       147.0                 5.1        FAST  \n",
       "2          38     145.5       147.0                -1.0          OK  \n",
       "3          11     151.3       147.0                 2.9        FAST  \n",
       "4          47     148.0       147.0                 0.7          OK  \n",
       "5          45     146.3       147.0                -0.5          OK  \n",
       "6         112     147.6       147.0                 0.4          OK  \n",
       "7          24     145.6       147.0                -1.0          OK  \n",
       "8          24     146.6       147.0                -0.2          OK  \n",
       "9          17     145.0       147.0                -1.4          OK  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>target_words</th>\n",
       "      <th>new_length</th>\n",
       "      <th>rate_wpm</th>\n",
       "      <th>target_wpm</th>\n",
       "      <th>rate_deviation_pct</th>\n",
       "      <th>rate_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8d7a71c7-84e7-4be4-addf-8d69c3d7c0b3</td>\n",
       "      <td>9.680</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>148.8</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fc98262d-4ef3-429a-9d85-3057c5d999c9</td>\n",
       "      <td>3.495</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>154.5</td>\n",
       "      <td>147.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>FAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa4deb66-623c-4c45-9ba3-d99bbe9418bd</td>\n",
       "      <td>15.671</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>145.5</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>342b2806-3672-4035-8971-548b78a169f0</td>\n",
       "      <td>4.363</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>151.3</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>FAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1bdfd4a-7283-49b6-95ba-b7de7bf4b49c</td>\n",
       "      <td>19.049</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>148.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40fe5576-2765-4e75-b2d4-e9e779ec338d</td>\n",
       "      <td>18.455</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>146.3</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2caf09cf-05c5-44a8-87d7-c53cbc52abff</td>\n",
       "      <td>45.514</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>147.6</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5063a8c7-38bf-488b-b18f-eb94001b248c</td>\n",
       "      <td>9.890</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>145.6</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54091848-748e-4a99-aea0-1e2eb40988d3</td>\n",
       "      <td>9.820</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>146.6</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adf33389-a2c8-417b-860d-760bb039ff30</td>\n",
       "      <td>7.035</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>145.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export -> v4_audit_vitesse.csv\n"
     ]
    }
   ],
   "execution_count": 427
  },
  {
   "cell_type": "code",
   "id": "db516c46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:36:07.256852900Z",
     "start_time": "2025-09-28T22:18:24.592612Z"
    }
   },
   "source": [
    "\n",
    "# (10) Préparation payload & patch Rask (dry‑run par défaut)\n",
    "def _row_to_segment_patch(row: pd.Series, dst_lang: str, include_timing: bool = False) -> dict:\n",
    "    seg = {\"id\": str(row[\"segment_id\"]), \"dst\": {\"text\": str(row[\"new_text\"]), \"lang\": dst_lang}}\n",
    "    if include_timing:\n",
    "        if pd.notna(row.get(\"start\")): seg[\"start\"] = str(row[\"start\"])\n",
    "        if pd.notna(row.get(\"end\")):   seg[\"end\"]   = str(row[\"end\"])\n",
    "    return seg\n",
    "\n",
    "def build_segments_payload_for_patch(df: pd.DataFrame,\n",
    "                                     dst_lang: str,\n",
    "                                     indices: list[int],\n",
    "                                     include_timing: bool = False) -> list[dict]:\n",
    "    subset = df.loc[indices]\n",
    "    subset = subset[subset[\"new_text\"].notna() & (subset[\"new_text\"].astype(str).str.strip().str.len() > 0)]\n",
    "    return [_row_to_segment_patch(row, dst_lang, include_timing=include_timing) for _, row in subset.iterrows()]\n",
    "\n",
    "def patch_segments_text(headers: dict,\n",
    "                        project_id: str,\n",
    "                        segments: list[dict],\n",
    "                        batch_size: int = 100,\n",
    "                        dry_run: bool = True,\n",
    "                        sleep_between: float = 0.4) -> None:\n",
    "    url = PATCH_SEGMENTS_URL.format(project_id=project_id)\n",
    "    total = len(segments)\n",
    "    batches = math.ceil(total / batch_size)\n",
    "    for b in range(batches):\n",
    "        chunk = segments[b*batch_size:(b+1)*batch_size]\n",
    "        if dry_run:\n",
    "            print(f\"[DRY-RUN] PATCH {b+1}/{batches} -> {url} ({len(chunk)} segments)\")\n",
    "            preview = [{\"id\": s[\"id\"],\n",
    "                        \"dst_len\": len(str(s.get(\"dst\",{}).get(\"text\",\"\")).split()),\n",
    "                        \"dst_lang\": s[\"dst\"].get(\"lang\"),\n",
    "                        \"start\": s.get(\"start\"), \"end\": s.get(\"end\")} for s in chunk]\n",
    "            display(pd.DataFrame(preview))\n",
    "            continue\n",
    "        resp = requests.patch(url, headers={**headers,\"Content-Type\":\"application/json\"},\n",
    "                              json={\"segments\": chunk}, timeout=60)\n",
    "        if resp.status_code >= 400:\n",
    "            try: print(\"Erreur serveur:\", json.dumps(resp.json(), ensure_ascii=False, indent=2))\n",
    "            except Exception: print(\"Erreur brute:\", resp.text)\n",
    "            resp.raise_for_status()\n",
    "        print(f\"OK PATCH {b+1}/{batches}: {len(chunk)} segments\")\n",
    "        time.sleep(sleep_between)\n",
    "\n",
    "def generate_project(headers: dict, project_id: str) -> dict:\n",
    "    r = requests.post(GENERATE_URL.format(project_id=project_id), headers=headers, timeout=60)\n",
    "    if r.status_code >= 400:\n",
    "        try: print(\"Erreur serveur generate:\", json.dumps(r.json(), ensure_ascii=False, indent=2))\n",
    "        except Exception: print(\"Erreur brute generate:\", r.text)\n",
    "        r.raise_for_status()\n",
    "    print(\"Génération lancée.\")\n",
    "    return r.json()\n",
    "\n",
    "payload = build_segments_payload_for_patch(df, dst_lang=dst_lang, indices=indices_to_process, include_timing=INCLUDE_TIMING)\n",
    "print(\"Segments à patcher:\", len(payload))\n",
    "\n",
    "# Dry‑run pour inspection (mettre DRY_RUN=False pour envoyer)\n",
    "patch_segments_text(HEADERS, project_id, payload, dry_run=False)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segments à patcher: 10\n",
      "OK PATCH 1/1: 10 segments\n"
     ]
    }
   ],
   "execution_count": 428
  },
  {
   "cell_type": "code",
   "id": "6bc191b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:36:07.260866300Z",
     "start_time": "2025-09-28T22:18:25.904324Z"
    }
   },
   "source": [
    "\n",
    "# (11) Exports finaux\n",
    "path_dir_output = os.path.join(os.getcwd(), PROJECT_SELECTOR)\n",
    "os.makedirs(path_dir_output, exist_ok=True)\n",
    "out_csv = os.path.join(path_dir_output, \"v4_transcription_postgen.csv\")\n",
    "df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"CSV écrit ->\", out_csv)\n",
    "\n",
    "out_payload = os.path.join(path_dir_output, \"v4_segments_payload.json\")\n",
    "try:\n",
    "    with open(out_payload, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "    print(\"Payload JSON écrit ->\", out_payload)\n",
    "except Exception as e:\n",
    "    print(\"Aucun payload à écrire ou erreur:\", e)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV écrit -> /mnt/c/Users/Utilisateur/PycharmProjects/lumierelearning/notebook/2_-_Presentation_des_cires_KtwWjO/v4_transcription_postgen.csv\n",
      "Payload JSON écrit -> /mnt/c/Users/Utilisateur/PycharmProjects/lumierelearning/notebook/2_-_Presentation_des_cires_KtwWjO/v4_segments_payload.json\n"
     ]
    }
   ],
   "execution_count": 429
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
